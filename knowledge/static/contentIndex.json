{"Homelab/Hardware":{"title":"Hardware","links":[],"tags":[],"content":"Hardware\nMinisForum BD790i\n\nAMD Ryzen 9 7945HX\n\n16 cores, 32 threads\nZen 4 architecture\n2.5 GHz - up to 5.4 GHz under boost\nL1/2/3 caches: 1/16/64 MB\n55-75W (AMD Configurable TDP)\nTSMC 5nm FinFET\n\n\nIntegrated AMD Radeon 610M Grafik\n\n2 * SK hynix 32GB DDR5 5600MHz\n2 * WD Blue SN580 PCIe4.0 (500GB + 2TB)\nCorsair SF600 Platinium\nDeLock 89017 bifurcation\n\n4 * WD Blue SN580 PCIe4.0 2TB\n\nFractal Terra (SFX-L, SFX, Mini ITX)\n\n2 * Noctua NF-A12x25 PWM\n\nDimensions\nMotherboard: 18 x 18 x 12h\nPSU: 122w x 65h x 102d mm\n20cm if PSU under board, 26 if next to it\nCPU cooler (CPU + rad + fan): 67mm\nTerra case: 343 x 153 x 198 mm"},"Homelab/Homelab":{"title":"Homelab","links":["Homelab/Hardware","Homelab/Internet-Infrastructure/Domain-Name,-DNS,-FQDN","Homelab/OS-and-Virtualization/Virtualization","Homelab/OS-and-Virtualization/Proxmox","Homelab/OS-and-Virtualization/TrueNAS","Homelab/OS-and-Virtualization/Docker","Homelab/Services/Pi-Hole","Homelab/Services/Homelab-Services","Homelab/Services/Nginx-Proxy-Manager-(NPM)","Homelab/Services/Wireguard","Homelab/Services/Cloudflared","Homelab/Services/Homelab-Networking","Homelab/Services/Mailrise","Homelab/Services/Diun","Homelab/Security/fail2ban","Homelab/Internet-Infrastructure/Continuous-Delivery-of-website","Homelab/Services/Uptime-Kuma","Homelab/Storage/iSCSI","Homelab/Storage/Network-Shares","Homelab/Storage/NVMe","Homelab/Storage/PCIe","Homelab/Storage/SCSI","Homelab/Storage/SATA","Homelab/Storage/XFS","Homelab/Storage/ZFS","Homelab/Storage/ZFS-VDEV--and--Storage","Homelab/Storage/ZFS-Dataset--and--Zvol","Homelab/Internet-Infrastructure/Serve-static-files-through-NPM"],"tags":[],"content":"Stuff to look into\n\n Logs monitoring: Prometheus + Grafana\n Traefik instead of NPM\n Build a comments section\n Install an AI platform\n ZFS replication\n Replace most of the config files by links to their public repo\n Play with Coolify\n Look into Docker Swarm\n\nBuilding a secure private server from scratch\n\nHardware\nDomain Name &amp; Global DNS\nVirtualization paradigm\n\nServers setups (Hypervisor, NAS, Docker and more)\n\n\nLocal networking (DNS, DHCP, Ad-blocking)\nDeploy Services\nSecurity\n\nAccess control &amp; auto-TLS everywhere\nDouble proxy, VPN and tunnels\nAdvanced Docker networking\nGet notified about services and software updates\nIP rules\n\n\nContinuous Delivery of website\nMonitoring\n\nServices Uptime\nLogs &amp; metrics (todo)\n\n\n\nSide quests\nDisks, Mounts, FSs\n\nDisks IOMMU\niSCSI\nNetwork Shares\nNVMe, PCIe\nSCSI, SATA\nXFS, ZFS\nZFS VDEV &amp; Storage\nZFS Dataset &amp; Zvol\n\nStatic Web hosting\n\nServe static files through NPM\nContinuous Delivery of website\nObsidian\nQuartz\n"},"Homelab/Internet-Infrastructure/Cloudflare":{"title":"Cloudflare","links":["Homelab/Internet-Infrastructure/DynDNS","Homelab/Security/fail2ban"],"tags":[],"content":"Quid\nCloudflare is a technology company that provides a wide range of internet services focused on security, performance, and reliability. Here are the key aspects of what Cloudflare does:\nContent Delivery Network (CDN):\nCloudflare operates a global network of data centers that cache and deliver website content to visitors from the nearest location, significantly improving loading speeds.\nSecurity Services:\n\nDDoS protection to defend websites against distributed denial-of-service attacks\nWeb Application Firewall (WAF) to filter out malicious traffic\nBot management to prevent automated abuse\nSSL/TLS encryption to secure data in transit\n\nPerformance Features:\n\nLoad balancing to distribute traffic across multiple servers\nSmart routing to optimize data paths\nImage and code optimization\nCaching and compression to reduce bandwidth usage\n\nDeveloper Tools:\n\nCloudflare Workers (serverless computing platform)\nCloudflare Pages (JAMstack platform for frontend developers)\nDNS services with built-in security features\nZero Trust security solutions for enterprise applications\n\nCloudflare also offers services for businesses of all sizes, from free basic protection for small websites to enterprise-grade solutions for large organizations. The company has become particularly notable for its ability to mitigate some of the largest DDoS attacks in internet history and its role in helping protect websites against emerging security threats.\nSource: Claude.ai\nWhy\nIn the context of this homelab, Cloudflare is used as/for:\n\nDNS host (website, email, etc.)\n\nIncluding as DynDNS provider for Wireguard\n\n\nReverse proxy and tunnel for one137.dev\n\nIncluding DDoS and caching\n\n\nSecurity / WAF\n\nRate limiting rules\nIP access rules (synced with fail2ban)\n\n\nAnalytics\n"},"Homelab/Internet-Infrastructure/Continuous-Delivery-of-website":{"title":"Continuous Delivery of website","links":["Homelab/Services/Wireguard"],"tags":[],"content":"The goal is to implement the ubiquitous “push to deploy” – a simple continuous delivery mechanism that automatically redeploys a git repo when a commit is pushed to its master branch.\nIn our case, the server on which the git repo lives is only accessible through a Wireguard VPN. The aim with the chosen methods is to be simple and secure, while requiring as little setup as possible (esp. regarding installations &amp; modifications of the repo’s server).\nMethod 1: GitHub Actions\nTL;DR :\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkey name/home/github-actions/.ssh/github.com’s repo settingsSSH github-deploy-key_REPOpriv &amp; pub filespub in Deploy keys: github-deploy-key_REPOSSH id_github-actionspub in authorized_keyspriv in Secrets: WEBSERVER_SSH_IDWG github-actions.conf(download from WG server)conf in Secrets: WIREGUARD_CONFIG\nDetails:\n\nCreate a user account for the git workflows.\n\nIf user account already exists, skip this step and run other steps with sudo in /home/github-actions\nsudo adduser github-actions # use simple passwd – will be removed\nsudo usermod -aG dockeruser github-actions # needs write access to /srv/docker/volumes/one137-web\nsu - github-actions\nDo all steps below as user github-actions, then passwd -l to lock account\n\n\nSet up deploy key (web server → github repo pull)\n\ncat &gt;&gt; .ssh/config (note this config allows for multiple deploy keys for github.com, needed if handling &gt;1 repos)\n\nHost github.com-one137-web\n\tHostname github.com\n\tIdentityFile ~/.ssh/github-deploy-key_one137-web\n\n\nNote: The repo needs to use SSH not HTTPS for the remote\n\ngit clone git@github.com-one137-web:one137/web.git one137-web/, or if already set up:\ngit remote set-url origin git@github.com-one137-web:one137/web.git\n\n\nssh-keygen -t ed25519 -C &quot;github-deploy-key_one137-web&quot; -f .ssh/github-deploy-key_one137-web\nchmod 600 .ssh/github-deploy-key_one137-web\ncat .ssh/github-deploy-key_one137-web.pub # and copy\nGo to GitHub &gt; Repo &gt; Settings &gt; Deploy keys &gt; Add deploy key\nPaste file name and outputted PUB key. Save\n\n\nSet up Wireguard config (github actions → wireguard endpoint)\n\nGenerate a new Wireguard config for GitHub Actions in the Wireguard Server\nDownload and view the config file. Make sure no IPv6 is specified anywhere. Copy.\nGo to GitHub &gt; Secrets and variables &gt; Actions &gt; New Repo secret\nName it “WIREGUARD_CONFIG” and paste copied config\n\n\nSet up actions’ key (wireguard endpoint → web server)\n\nssh-keygen -t ed25519 -C &quot;id_github-actions&quot; -f id_github-actions\ncat id_github-actions.pub &gt;&gt; .ssh/authorized_keys\ncat id_github-actions # and copy private key\nrm id_github-actions id_github-actions.pub\nGo to GitHub &gt; Secrets and variables &gt; Actions &gt; New Repo secret\nName it “WEBSERVER_SSH_ID” and paste outputted private key. Save\n\n\nsudo passwd -l github-actions # to lock password-login for account\nCreate and commit one137-web/.github/workflows/deploy.yml:\n\nname: Deploy via WireGuard\non:\n  push:\n    branches:\n      - master\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Set up WireGuard\n        run: |\n          sudo apt-get install -y wireguard\n          echo &quot;${{ secrets.WIREGUARD_CONFIG }}&quot; &gt; ~/wg0.conf\n          sudo wg-quick up ~/wg0.conf\n \n          # Extract DNS server from WireGuard config and append to resolv.conf\n          DNS_SERVER=$(grep &quot;DNS = &quot; ~/wg0.conf | cut -d &quot;=&quot; -f2 | tr -d &#039; &#039;)\n          if [ ! -z &quot;$DNS_SERVER&quot; ]; then\n            echo &quot;nameserver $DNS_SERVER&quot; | sudo tee -a /etc/resolv.conf\n          fi\n \n      - name: Set up SSH Key\n        run: |\n          mkdir ~/.ssh\n          echo &quot;${{ secrets.WEBSERVER_SSH_ID }}&quot; &gt; ~/.ssh/id_rsa\n          chmod 600 ~/.ssh/id_rsa\n          ssh-keyscan -H dockerhost &gt;&gt; ~/.ssh/known_hosts\n \n      - name: Deploy Application\n        run: |\n          ssh github-actions@dockerhost &quot;cd /srv/docker/volumes/one137-web &amp;&amp; git fetch origin master &amp;&amp; git reset --hard origin/master&quot;\n \n      - name: Tear Down WireGuard\n        if: always()\n        run: |\n          sudo wg-quick down ~/wg0.conf\nMethod 2: GitHub Webhook\nThis methods put less load on GitHub and more on the web server itself, but doesn’t require Wireguard (that is, no need to be able to log into the web server from the WAN). It would probably scale better to multi repos as well.\nSteps 1 and 2 from Method 1 GitHub Actions should be identical. 3 and 4 are replaced by doing some Nginx setup, installing some apps on the server and writing a small script.\nThe idea is:\n\nCreate a Web Hook in the repo’s settings with a payload URL of one137.dev/github-hook or whatever\nConfigure a location in Nginx to match that URL\nProxy_pass it to a python/perl/whatever server &amp; script that will trigger a git fetch in the repo’s folder\n\nTo avoid running an extra server, fcgiwrap can be used to “directly” execute a e.g. shell script from Nginx\n\n\n"},"Homelab/Internet-Infrastructure/Domain-Name,-DNS,-FQDN":{"title":"Domain Name, DNS, FQDN","links":["tags/TODO","Homelab/Services/Homelab-Networking"],"tags":["TODO"],"content":"TODO\nHomelab Networking"},"Homelab/Internet-Infrastructure/DynDNS":{"title":"DynDNS","links":["tags/TODO","Homelab/Internet-Infrastructure/Domain-Name,-DNS,-FQDN"],"tags":["TODO"],"content":"TODO\nDomain Name, DNS, FQDN"},"Homelab/Internet-Infrastructure/Forward-Proxy":{"title":"Forward Proxy","links":["Homelab/Internet-Infrastructure/Reverse-Proxy","tags/TODO"],"tags":["TODO"],"content":"A forward proxy sits between users and the internet, acting as an intermediary for outbound requests. When users want to access external websites, their traffic goes through the forward proxy first. This setup allows to monitor/control internet usage, cache common requests, and mask users’ original IP addresses.\nIt is the opposite of a Reverse Proxy.\nPrivate forward proxy to mask IP addresses\nThis can be used so that internal servers can all access the internet through a common IP when accessing external services which use IP whitelists.\n# ...\n \nhttp {\n\t# ...\n\t\n    resolver 1.1.1.1 1.0.0.1 valid=300s;\n    resolver_timeout 5s;\n \n    map $request $forward_scheme {\n        &quot;~ https://&quot; &quot;https&quot;;\n        default      &quot;http&quot;;\n    }\n \n    log_format fwd\n    \t&#039;[$time_local] $proxy_add_x_forwarded_for &quot;$http_user_agent&quot; - status=$status sent=$bytes_sent - &quot;$request&quot;&#039;;\n \n    server {\n        listen 8080;\n    \n    \taccess_log /var/log/nginx/fwd-proxy.access.log fwd;\n        error_log /var/log/nginx/fwd-proxy.error.log notice;\n \n        allow 172.16.0.0/16; # also restricted in the env&#039;s firewall\n        deny all;\n \n        location / {\n            proxy_pass $forward_scheme://$http_host$request_uri;\n \n            proxy_set_header Host $http_host;\n \n            proxy_ssl_server_name on;\n            proxy_ssl_protocols TLSv1.2 TLSv1.3;\n            proxy_ssl_verify off;\n \n            proxy_connect_timeout 20s;\n            proxy_send_timeout 20s;\n\t        proxy_read_timeout 20s;\n        }\n    }\n}\nNotes:\n\nTODO\n"},"Homelab/Internet-Infrastructure/Introductory-presentation/1-–-IP,-Routes,-Subnets":{"title":"1 – IP, Routes, Subnets","links":[],"tags":[],"content":"Goal\nUnderstand the output of commands such as\n\nip addr (ifconfig on macOS)\nip route and\nss -tulpn (lsof -nP -i4TCP -sTCP:LISTEN on macOS)\n\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host proto kernel_lo\n       valid_lft forever preferred_lft forever\n\n2: wg0: &lt;POINTOPOINT,NOARP,UP,LOWER_UP&gt; mtu 1420 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/none\n    inet 10.8.0.1/24 scope global wg0\n       valid_lft forever preferred_lft forever\n\n417: eth0@if418: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:ac:14:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.20.0.3/16 brd 172.20.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\nCOMMAND   TYPE  NODE  NAME\nnode      IPv4   TCP  *:3000 (LISTEN)\nmongod    IPv4   TCP  127.0.0.1:3001 (LISTEN)\nsyncthing IPv4   TCP  127.0.0.1:8384 (LISTEN)\n\n\nIP Addresses\n\nEvery device on the internet needs a unique address\nLike a phone number or postal address for your computer\nTwo versions: IPv4 (e.g., 192.168.1.10) and IPv6 (e.g., 2001:0db8:85a3:0000:0000:8a2e:0370:7334)\nIPv4 has ~4.3 billion addresses, IPv6 has 340 undecillion (10^38)\n\nflowchart LR\n    A[Computer A\\n192.168.1.10] &lt;--&gt;|IP packets| B[Computer B\\n192.168.1.20]\n\n\nMAC vs IP Addresses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristicMAC AddressIP AddressFormat48-bit hexa (aa:bb:cc:dd:ee:ff)32-bit dec for IPv4, 128-bit for IPv6AssignmentPermanently assigned by manufacturerLogically assigned and changeablePurpose”Last hop” delivery on local network segmentsEnd-to-end routing across networksScopeOnly meaningful within local networkGlobally meaningfulLayerLayer 2 (Data Link)Layer 3 (Network)\nAnalogy: a person’s name VS a building’s address.\nARP requests allow to find the MAC address for an IP.\n\nSubnets\nSubnet:\n\nLogical division of an IP network\nAllows for better network organization and security\n\nSubnet mask:\n\nDefines which part of the IP is network vs host\nCommon mask: 255.255.255.0 (or /24)\n\nNetwork portion: 192.168.1\nHost portion: 0-255\n\n\nCIDR (Classless Inter-Domain Routing):\n\nReplaces older class-based system (Class A, B, C)\nIPs have 32 bits: 192.168.1.10 = 11000000.10101000.00000001.00001010\n/24 means first 24 bits (192.168.1) are network portion, /16 for 172.1, etc.\nMore flexible allocation of network sizes (e.g. /28 for 16 IPs)\n\n\n\nflowchart TD\n\tS1[Subnet 192.168.1.0/24\\nEngineering]\n\tS2[Subnet 192.168.2.0/24\\nMarketing]\n\tS3[Subnet 172.16.0.0/16\\nCampus 2]\n\n\nNetwork Switches\n\nA switch connects multiple devices on a local network (same subnet)\nActs as a traffic controller, directing data only to intended recipients\nMore efficient than direct connections or older hubs\nLearns which devices are connected to each port\n\nflowchart TD\n    S[Switch] --- A[Engineering PC A\\n192.168.1.10]\n    S --- B[Engineering PC B\\n192.168.1.20]\n    S --- C[Engineering PC C\\n192.168.1.30]\n    S --- P[Engineering Printer\\n192.168.1.40]\n\n\nGateways and Routers\n\nGateway: Door between different networks (local network and the internet, or different subnets)\nRouter: Physical device that acts as a gateway\nRoutes traffic between networks using routing tables\nNetwork Address Translation (NAT) allows multiple local devices to share one public IP\n\nflowchart TD\n    R[Router] --- SW1[Switch 1]\n    R --- SW2[Switch 2]\n    R --- SW3[Switch 3]\n    SW1 --- S1[Subnet 192.168.1.0/24\\nEngineering]\n    SW2 --- S2[Subnet 192.168.2.0/24\\nMarketing]\n    SW3 --- S3[Subnet 172.16.0.0/16\\nCampus 2]\n\nflowchart LR\n    subgraph Local Network\n        C1[192.168.1.10] --&gt; R\n        C2[192.168.1.20] --&gt; R\n    end\n    R[Router\\nLocal: 192.168.1.1\\nPublic: 203.0.113.1] --&gt; I[Internet]\n\n\nDHCP (Dynamic Host Configuration Protocol)\n\nAutomatically assigns IP addresses to devices on a network\nNo manual configuration needed - “plug and play” networking\nAlso provides other network settings (subnet mask, gateway, DNS servers)\nTypical process: DISCOVER → OFFER → REQUEST → ACKNOWLEDGE\n\nsequenceDiagram\n    participant C as Client\n    participant D as DHCP Server\n    C-&gt;&gt;D: DISCOVER\n    Note over C,D: &quot;I need an IP address&quot;\n    D-&gt;&gt;C: OFFER\n    Note over C,D: &quot;You can use 192.168.1.50&quot;\n    C-&gt;&gt;D: REQUEST\n    Note over C,D: &quot;I&#039;d like to use that IP&quot;\n    D-&gt;&gt;C: ACKNOWLEDGE\n    Note over C,D: &quot;It&#039;s yours for X hours&quot;\n\n\nBroadcast address\nSpecial address to reach all devices in a subnet\n\nTypically ends in .255 (for /24 networks)\nUsed for network discovery and some network protocols\nExample: 192.168.1.255 reaches all devices in 192.168.1.0/24\n\nExample use cases:\n\nDHCP requests (when a device first joins a network and needs an IP)\nARP requests (to find the MAC address for an IP)\nNetwork printer discovery\nSmart home devices announcing themselves on the network\nWake-on-LAN\n\n\nNetwork Interfaces\n\nPhysical or virtual connections between a device and a network\n\nAnalogy:\n\ndevice = city, IP network = train network, interface = train station\nParis has multiple stations: Gare du Nord, Gare de Lyon, etc. The correct one (and so the correct “route”) needs to be chosen to reach a given other city\n\n\n\n\nCommon types:\n\nEthernet (eth0, eth1): Physical wired connections\nWireless (wlan0): WiFi connections\nLoopback (lo): Special interface for local communication\n\n\nEach interface has:\n\nA MAC address (for physical interfaces)\nOne (or more) IP addresses\nMTU and various flags indicating its state and capabilities\n\n\n\n\nLoopback Interface and Address\n\nSpecial interface (lo) for local communication\nAlways available, even if network hardware fails\nStandard IP: 127.0.0.1 (IPv4) or ::1 (IPv6)\nHostname “localhost” typically resolves to 127.0.0.1\n\nExample use cases:\n\nTesting network services locally\nWeb developers running local development servers\nDatabase connections to local instances\nInter-process communication via network protocols\nNetwork application testing without network access\nServices that only need to be accessible from the same machine\n\n\nNetwork Ports\n\nAllows multiple network services on same IP address\n16-bit number (0-65535) that identifies a specific service\nOften written after IP with colon: 192.168.1.10:80\nWell-known ports (0-1023): 80/443: HTTP(S), 22: SSH, 53: DNS, 25: SMTP\nDynamic/private ports (49152-65535): Assigned automatically by client applications when making connections\nIn the train station analogy, the port would probably be the track number\n\nflowchart LR\n    subgraph &quot;Server 192.168.1.99&quot;\n        direction TB\n        W[Web Server&lt;br/&gt;:80] \n        S[SSH Server&lt;br/&gt;:22]\n    end\n    C1[Client A 192.168.1.10&lt;br/&gt;:49152] --&gt; W\n    C2[Client B 192.168.1.11&lt;br/&gt;:59745] --&gt; S\n\n\nBrief intro to TCP (Transmission Control Protocol)\n\nProvides reliable, ordered data delivery between applications\nConnection-oriented: requires setup before data transfer\nEach connection identified by 4 values:\n\nSource IP:Port\nDestination IP:Port\n\n\nKey features:\n\nGuarantees delivery (retransmits lost packets)\nMaintains packet order\nControls flow to prevent overwhelming receiver\n\n\n\nsequenceDiagram\n    participant C as Client&lt;br/&gt;192.168.1.10:49152\n    participant S as Server&lt;br/&gt;142.251.167.99:80\n    C-&gt;&gt;S: SYN\n    Note over C,S: Can I start a connection?\n    S-&gt;&gt;C: SYN-ACK\n    Note over C,S: Yes, I&#039;m ready\n    C-&gt;&gt;S: ACK\n    Note over C,S: Connection ESTABLISHED\n    Note over C,S: Now we can send data\n\n\nNetwork Address Translation (NAT)\n\nAllows multiple internal devices to share one public IP address\nProvides an additional layer of security by hiding internal network structure\nRouter maintains a NAT table tracking:\n\nInternal IP:port &lt;&gt; External IP:port\nCurrent connection status\n\n\nMost home and small business networks use NAT\nWithout NAT, we would have run out of IPv4 addresses long ago\n\nIf two local PCs talk to the same server 142.251.167.99:80, the router’s connection table may look like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIDStateProtocolLAN address (PC)WAN address (router)Remote addressTTL (s)Packets in/out12ESTABLISHEDTCP192.168.1.10:1234203.0.113.1:5678142.251.167.99:80360042/3813ESTABLISHEDTCP192.168.1.55:2345203.0.113.1:6789142.251.167.99:80360015/12\n\nExample: Putting things together\nLocal PC 192.168.1.10 wants to view the local network website at 192.168.1.99:80:\nsequenceDiagram\n    participant PC as Computer&lt;br/&gt;IP: 192.168.1.10&lt;br/&gt;MAC: aa:bb:cc&lt;br/&gt;Interface: eth0\n    participant S as Switch\n    participant WS as Web Server&lt;br/&gt;IP: 192.168.1.99&lt;br/&gt;MAC: ff:ff:ff&lt;br/&gt;Interface: eth0\n    PC-&gt;&gt;PC: Which interface for 192.168.1.99? =&gt; eth0&lt;br/&gt;Is it on my subnet? =&gt; Yes\n    PC-&gt;&gt;S: ARP: Who has 192.168.1.99?\n    Note over S: Switch learns PC&#039;s MAC&lt;br/&gt;is on physical port 1\n    S-&gt;&gt;WS: ARP: Who has 192.168.1.99?\n    WS-&gt;&gt;S: ARP: I am 192.168.1.99&lt;br/&gt;MAC: ff:ff:ff\n    Note over S: Switch learns Web Server&#039;s MAC&lt;br/&gt;is on physical port 3\n    S-&gt;&gt;PC: ARP: 192.168.1.99 is at&lt;br/&gt;MAC ff:ff:ff\n    PC-&gt;&gt;S: HTTP request to 192.168.1.99:80&lt;br/&gt;from 192.168.1.10:1234&lt;br/&gt;via MAC ff:ff:ff\n    S-&gt;&gt;WS: HTTP request to 192.168.1.99:80&lt;br/&gt;from 192.168.1.10:1234&lt;br/&gt;via MAC ff:ff:ff\n    WS-&gt;&gt;S: HTTP response to 192.168.1.10:1234&lt;br/&gt;from 192.168.1.99:80&lt;br/&gt;via MAC aa:bb:cc\n    S-&gt;&gt;PC: HTTP response to 192.168.1.10:1234&lt;br/&gt;from 192.168.1.99:80&lt;br/&gt;via MAC aa:bb:cc\n\n\n\nExample: Putting things together\nLocal PC 192.168.1.10 wants to view the internet website at 142.251.167.99:80:\nsequenceDiagram\n    participant PC as Computer&lt;br/&gt;IP: 192.168.1.10&lt;br/&gt;MAC: aa:bb:cc&lt;br/&gt;Interface: eth0\n    participant S as Switch\n    participant R as Router&lt;br/&gt;Local IP: 192.168.1.1&lt;br/&gt;Public IP: 203.0.113.1&lt;br/&gt;MAC: dd:ee:ff\n    participant I as Internet&lt;br/&gt;IP: 142.251.167.99\n    PC-&gt;&gt;PC: Which interface for 142.251.167.99? =&gt; eth0&lt;br/&gt;Is it on my subnet =&gt; No&lt;br/&gt;What&#039;s the gateway =&gt; 192.168.1.1\n    PC-&gt;&gt;S: ARP: Who has 192.168.1.1?\n    Note over S: Switch learns PC&#039;s MAC&lt;br/&gt;is on physical port 1\n    S-&gt;&gt;R: ARP: Who has 192.168.1.1?\n    R-&gt;&gt;S: ARP: I am 192.168.1.1&lt;br/&gt;MAC: dd:ee:ff\n    Note over S: Switch learns Router&#039;s MAC&lt;br/&gt;is on physical port 7\n    S-&gt;&gt;PC: ARP: 192.168.1.1 is at&lt;br/&gt;MAC dd:ee:ff\n    PC-&gt;&gt;S: Packet to 142.251.167.99&lt;br/&gt;from 192.168.1.10:1234&lt;br/&gt;via MAC dd:ee:ff\n    S-&gt;&gt;R: Packet to 142.251.167.99&lt;br/&gt;from 192.168.1.10:1234&lt;br/&gt;via MAC dd:ee:ff\n    Note over R: NAT: Remember this connection&lt;br/&gt;from 192.168.1.10:1234\n    R-&gt;&gt;I: Forward packet from&lt;br/&gt;203.0.113.1:5678&lt;br/&gt;to 142.251.167.99:80\n    I-&gt;&gt;R: Reply to 203.0.113.1:5678&lt;br/&gt;from 142.251.167.99:80\n    Note over R: NAT: Look up local IP:port&lt;br/&gt;matching 203.0.113.1:5678\n    R-&gt;&gt;S: Reply to MAC aa:bb:cc&lt;br/&gt;for 192.168.1.10:1234\n    S-&gt;&gt;PC: Reply to MAC aa:bb:cc&lt;br/&gt;for 192.168.1.10:1234\n"},"Homelab/Internet-Infrastructure/Reverse-Proxy":{"title":"Reverse Proxy","links":["Homelab/Services/Nginx-Proxy-Manager-(NPM)","Homelab/Internet-Infrastructure/Cloudflare","Homelab/Internet-Infrastructure/Forward-Proxy","Homelab/Services/Cloudflared","Homelab/Internet-Infrastructure/DynDNS"],"tags":[],"content":"A reverse proxy is a server that sits in front of internal services (such as web servers) and forwards client requests (e.g. from the internet) to them. It acts as an intermediary that can handle load balancing, SSL termination, caching, and security filtering.\nNginx and Cloudflare are famous examples of reverse proxies, both of which are used in this Homelab.\nIt’s the opposite of a Forward Proxy, which connects internal clients to the outer world.\nThe double reverse-proxy\nOne use of a reverse proxy is to hide one’s IP address. It’s (theoretically) impossible to figure out my home router’s address because it is shielded by Cloudflare. The DNS entry for one137.dev points to their server and this is all the user can know. When the user connects and asks for resources, Cloudflare transparently fetches them on the user’s behalf from my server, and serve them back as if they were stored on their own servers. (In one137’s case, this is further secured by using the Cloudflared tunnel, which means http ports are not even open on my router and no DNS record needs pointing to it).\nIt isn’t complicated to implement a reverse proxy that does the core of what Cloudflare does in this situation. It’s sometimes referred to as a “double reverse proxy”, because this proxy isn’t directly connected to any of your services. Rather, it’s connected to your primary reverse proxy: the one connected to your services on your LAN, through your router.\nHere’s a complete Nginx configuration for this purpose:\nuser nginx;\nworker_processes  auto;\nworker_rlimit_nofile 4096;\n \n# load_module modules/ngx_http_modsecurity_module.so; # See modsecurity below\n \nevents {\n    worker_connections  4096;\n    use epoll;\n}\n \nerror_log /var/log/nginx/system.log notice;\n \nhttp {\n    include mime.types;\n \n    gzip on;\n    gzip_types text/plain text/css application/json application/javascript application/xml image/svg+xml;\n    gzip_min_length 1024;\n \n    resolver 1.1.1.1 valid=300s;\n    resolver_timeout 5s;\n \n  \tserver {\n        listen 443 ssl http2;\n    \tlisten [::]:443 ssl http2;\n        server_name one137.dev;\n \n        ssl_certificate /var/lib/nginx/certs/fullchain.pem;\n        ssl_certificate_key /var/lib/nginx/certs/privkey.pem;\n \n        ssl_session_cache shared:SSL:10m;\n        ssl_session_tickets off;\n \n      \t# Block Exploits (TODO)\n \t \t# include conf.d/include/block-exploits.conf;\n \n        add_header Strict-Transport-Security &quot;max-age=63072000; includeSubDomains; preload&quot; always;\n        add_header X-Content-Type-Options &quot;nosniff&quot;;\n        add_header X-Frame-Options &quot;SAMEORIGIN&quot;;\n        add_header Referrer-Policy &quot;no-referrer-when-downgrade&quot;;\n \n        location / {\n            # modsecurity on; # (TODO)\n      \n\t\t\taccess_log /var/log/nginx/revprox.access.log;\n\t\t\terror_log /var/log/nginx/revprox.error.log notice;\n \n            add_header X-Served-By $host;\n      \n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            proxy_set_header Host one137.dev; # While SECRETSUBDOMAIN.one137.dev points to the router&#039;s public IP, one137.dev is the host configured in NPM\n \n      \t\tproxy_ssl_server_name on;\n   \t\t\tproxy_ssl_protocols TLSv1.3;\n      \t\t\n            proxy_pass https://SECRETSUBDOMAIN.one137.dev$request_uri;\n        }\n    }\n \n    server {\n        listen 80;\n        listen [::]:80;\n        server_name one137.dev;\n        return 301 https://$host$request_uri;\n    }\n}\nBesides this Nginx instance running somewhere in the cloud, the following is needed:\n\nA public static IP address associated with Nginx\nA static DNS A record that point yourwebsite.com to that Nginx IP\nA DynDNS A record that points SECRETSUBDOMAIN.yourwebsite.com to your router’s public IP (make SECRETSUBDOMAIN hard to guess)\nPort 443 open on your router and forwarding traffic to your internal reverse proxy\nYou’ll need to deal with your SSL certificates’ renewals.\n\nOne can easily have all this running for just a few dollars per month. That being said, Cloudflare (or other comparable services) is free and provides additional layers of security, so it is a good option."},"Homelab/Internet-Infrastructure/Serve-static-files-through-NPM":{"title":"Serve static files through NPM","links":["Homelab/Security/fail2ban","Homelab/Internet-Infrastructure/Continuous-Delivery-of-website"],"tags":[],"content":"\nAdd Proxy Host one137.dev → http://STATIC_FILES:1 (name doesn’t matter)\nActivate Block Exploits and SSL as usual\n\nNote Access rules are not applied. If needed, they should go in the advanced tab under location /, for example (IPs should match those in Create Access List):\n\n\n\n\tallow 192.168.1.1/24;\n\tallow 172.21.0.2/32; # cloudflared\n\tallow 172.20.0.3/32; # wg-easy\n\tdeny all;\n\nIn Advanced tab, add (see Setup NPM for the logs, and X is the proxy number):\n\n\tlocation / {\n\t\troot /data/nginx/custom/one137-web;\n\t\ttry_files $uri $uri.html $uri/ =404;\n\t    access_log /data/logs/proxy-host-X_access.log default_plus_cf; # for fail2ban\n\t}\n\nCreate static web files\n\nin dockerhost’s /srv/docker/volumes/one137-web\nbind /srv/docker/volumes/one137-web:/srv/docker/volumes/one137-web in NPM’s stack\non dockerhost: sudo -u dockeruser ln -s /srv/docker/volumes/one137-web /srv/docker/volumes/npm/data/nginx/custom/one137-web\nSee Continuous Delivery of website for automation. If one137-web/ is cloned from a repo, use git clone git@github.com:username/one137-web.git instead of https, or manually set an SSH address for the remote.\n\n\n"},"Homelab/Internet-Infrastructure/WHOIS-and-Registrars":{"title":"WHOIS and Registrars","links":["tags/TODO","Homelab/Internet-Infrastructure/Domain-Name,-DNS,-FQDN","Homelab/Security/Homelab-Security"],"tags":["TODO"],"content":"TODO\nDomain Name, DNS, FQDN\nHomelab Security"},"Homelab/OS-and-Virtualization/Alpine-(Distro)":{"title":"Alpine (Distro)","links":["Homelab/OS-and-Virtualization/Debian","Homelab/OS-and-Virtualization/Virtualization","Homelab/OS-and-Virtualization/Linux-Systems-Setup"],"tags":[],"content":"Debian\nVirtualization\nLinux Systems Setup"},"Homelab/OS-and-Virtualization/Debian":{"title":"Debian","links":["Homelab/OS-and-Virtualization/Proxmox","Homelab/OS-and-Virtualization/Linux-Systems-Setup"],"tags":[],"content":"Setup as a VM in Proxmox\nLinux Systems Setup"},"Homelab/OS-and-Virtualization/Docker":{"title":"Docker","links":["Homelab/OS-and-Virtualization/Linux-Systems-Setup","Homelab/Storage/Network-Shares","Homelab/Services/Portainer","Homelab/OS-and-Virtualization/LXC"],"tags":[],"content":"Setup in Debian VM\nVM Creation\n\nCreate VM settings:\n\nStart at boot: Yes, Start order: order=2, up=30 to wait for TrueNAS’ shares\nMachine = 135, Disk = 64 GB\nCPU cores = 10, CPU type = x86-64-v4, RAM = 16384\n\n\nDebian install (terminal or graphic):\n\nleave root pwd empty\nGuided partitioning - use entire disk. All files in one partition.\nSoftware selection = SSH + Sys utils only\nGRUB boot loader on /dev/sda\n\n\n\nVM Setup\n\nConfigure the network interface from Proxmox console\nSee the rest of Linux Systems Setup\nSee SMB if SMB share needed.\n\nDocker Setup\nQuick install (or follow manual installation steps: docs.docker.com/engine/install/debian/#install-using-the-repository)\ncurl -fsSL get.docker.com | sh\nsudo docker run hello-world # To test\ndocs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user:\nsudo usermod -aG docker $USER &amp;&amp; logout\n# log back in...\nsudo systemctl enable docker.service &amp;&amp; sudo systemctl enable containerd.service\nCreate user and dir to manage bind-mount volumes:\nsudo adduser --disabled-login dockeruser\nsudo usermod -aG dockeruser $USER # needs log out\n \nsudo mkdir -p /srv/docker/volumes\nsudo chown -R dockeruser:dockeruser /srv/docker\nsudo chmod -R o-rwx /srv/docker\nsudo chmod -R g+s /srv/docker\nPortainer &amp; Stacks Setup\nPortainer\nDifference with standard LXCs\nSimilar to LXC. Early versions of Docker (pre 1.10) used LXC as the container execution driver.\nNow, Docker\n\nAdds a higher-level abstraction layer over Linux kernel features.\n\nUnlike LXC, which mimics a full OS environment with systemd/init, Docker removes system-level dependencies like init processes, reducing overhead.\n\n\nUses a Layered filesystem to create container images.\n\nContainers only use the top writable layer, sharing underlying read-only layers between multiple containers.\nSo Docker shareable containers usually include just the application and the minimal libraries required for it to function.\n\n\n\nAnd also (among others):\n\nEnforces stricter application-level isolation by default.\nSimplifies networking with built-in tools like bridge, host, and overlay networks.\n\nBut Docker is a lot about the components around the containers themselves. For example\n\nIts daemon dockerd\nIts API to interact with containers\nVarious tools to manage containers, images, networking, etc.\nDocker Hub\nDocker Compose\nDocker Swarm\n"},"Homelab/OS-and-Virtualization/Kali-Linux":{"title":"Kali Linux","links":["Homelab/Security/Security---Cryptography"],"tags":[],"content":"Quid\nDebian fork focused on security, penetration testing in particular. It comes pre-installed with lots of tools for security testing.\nGreat to learn about security and networking and testing the homelab from within.\nMisc\nSSH uses ed25519 keys by default."},"Homelab/OS-and-Virtualization/LXC":{"title":"LXC","links":["Homelab/OS-and-Virtualization/Docker"],"tags":[],"content":"Linux Containers (LXC) is an OS-level virtualization method for running multiple isolated Linux systems (containers) on a control host using a single Linux kernel.\nLXC combines the Linux kernel’s cgroups – feature that limits, accounts for, and isolates the resource usage (CPU, memory, disk I/O, etc) of a collection of processes – and support for isolated namespaces to provide an isolated environment for applications.\nEarly versions of Docker (pre 1.10) used LXC as the container execution driver.\nSource: Wikipedia\nRelated to Docker, see Difference with standard LXC s"},"Homelab/OS-and-Virtualization/Linux-Systems-Setup":{"title":"Linux Systems Setup","links":["Homelab/Security/fail2ban"],"tags":[],"content":"General\n# As root\n \nsudo apt update &amp;&amp; sudo apt upgrade -y\n \nsudo apt install unattended-upgrades # configure auto-updates for long-term sys\nsudo dpkg-reconfigure --priority=low unattended-upgrades\n \nsudo apt install openssh-server # if cannot ssh into system\nsudo apt install sudo vim bat curl ripgrep htop nmap # choose based on needs\n \nsudo adduser USER\nsudo usermod -aG sudo USER\n \nlogout\n \n# From remote:\nssh-copy-id -i ~/.ssh/id_rsa USER@SERVER\nssh USER@SERVER # Confirm no password asked\n \ngrep &quot;. ~/.bash_aliases&quot; .bashrc # If present, proceed, else edit .bashrc\ncat &gt;&gt; ~/.bash_aliases\n###\nalias ls=&#039;ls -F --color&#039;\nalias ll=&#039;ls -l&#039;\nalias l=&#039;ls -lh&#039;\nalias la=&#039;ls -A&#039;\nalias lla=&#039;ls -lA&#039;\n \nalias rm=&#039;rm -d&#039;\nalias bat=&quot;batcat&quot;\nalias cat=&#039;bat -p --paging=never&#039;\nalias less=&#039;bat -p --paging=always&#039;\n \nalias sudo=&#039;sudo &#039; # trick for aliases to work with sudo\n \nalias cpp=&quot;rsync -ah --progress&quot;\ncdd() { cd &quot;$1&quot; &amp;&amp; echo &quot;[[ $PWD ]]&quot; &amp;&amp; l | tail +2; }\nmvv() { mv &quot;$1&quot; &quot;$2&quot; &amp;&amp; cdd &quot;$2&quot;; }\nmkk() { mkdir &quot;$1&quot; &amp;&amp; cdd &quot;$1&quot;; }\n###\n \ncat &gt;&gt; .inputrc\n###\n&quot;\\e[A&quot;: history-search-backward\n&quot;\\e[B&quot;: history-search-forward\n&quot;\\C-v&quot;: &quot;\\C-w\\C-y\\C-y&quot;\n###\n \n# Additional security\n \nsudo passwd -l root # disable root login / su\n \nssh-keygen -t ed25519 # Create identity if needed\n \nsudo vim /etc/ssh/sshd_config # Strengthen SSH (once key-login confirmed!)\n###\nPasswordAuthentication no # edit\nChallengeResponseAuthentication no # add\n###\nsudo systemctl restart ssh\nSecurity\nFor further security for systems exposed to the world, consider setting up UFW and fail2ban.\nUFW\nNote: not compatible with Docker.\nsudo apt install ufw\nsudo ufw default deny incoming &amp;&amp; sudo ufw default allow outgoing\nsudo ufw allow ssh # &amp;&amp; sudo ufw allow 51820/udp etc\nsudo ufw enable &amp;&amp; sudo ufw status\nvim setup\nFor systems where files are edited often.\nmkdir -p ~/.vim/{swap,backups,undo}\nmv ~/.viminfo ~/.vim/\ncat &gt; ~/.vimrc\nset mouse=a             &quot; Enable mouse support in all modes\n \nset ssop-=options\t    &quot; Don&#039;t save options and mappings in sessions\nset ssop-=folds\t\t    &quot; Don&#039;t save folds in sessions\n \nset ignorecase          &quot; Case-insensitive search\nset smartcase \t\t    &quot; Use \\C for force case-sensitivness when searching all lower-case\n \nset tabstop=4           &quot; Tab key width\nset shiftwidth=4        &quot; Indentation width\nset softtabstop=4       &quot; Backspace deletes X spaces\nset autoindent          &quot; Copy indentation from previous line\n \nset incsearch           &quot; Show search matches while typing\nset hlsearch            &quot; Highlight search matches\n \nset scrolloff=4         &quot; Keep 4 lines visible above/below cursor\n \nset undofile            &quot; Enable persistent undo\nset undolevels=1000\t\t&quot; Maximum undo changes\nset undoreload=10000\t&quot; Maximum lines for undo on reload\n \nset switchbuf=useopen   &quot; Reuse existing windows when switching to a buffer\n \nset viminfo+=n~/.vim/viminfo\nset directory=~/.vim/swap//\nset backupdir=~/.vim/backups//\nset undodir=~/.vim/undo//\n \nset number relativenumber\nset colorcolumn=101\nhighlight LineNr ctermfg=darkgrey\nhighlight ColorColumn ctermbg=black guibg=black\n \nfiletype on\nsyntax on\n \nlet mapleader = &quot; &quot;     &quot; Set spacebar as the leader key for custom mappings\n \n&quot; Shift-Tab unindents in insert mode\ninoremap &lt;S-Tab&gt; &lt;C-D&gt;\n \n&quot; NERDtree like setup for netrw\nlet g:netrw_banner = 0\nlet g:netrw_liststyle = 3\nlet g:netrw_browse_split = 4\nlet g:netrw_altv = 1\nlet g:netrw_winsize = 25\nNetwork Interfaces Setup\nBelow are instructions to configure a manual network interface. But in most cases, simply reserving a static DHCP lease on the DHCP server should be enough.\nTraditional Debian-style\nip a or ifconfig to see existing interface names.\nAdd/edit an interface in /etc/network/interfaces:\nallow-hotplug INTERFACE\niface INTERFACE inet static\n\taddress 192.168.1.101\n\tnetmask 255.255.255.0\n\tgateway 192.168.1.1\n\nwhere INTERFACE is something like enp6s18, eth0, etc.\nAnd check that /etc/resolv.conf contains:\nnameserver 192.168.1.98\nnameserver 192.168.1.101\n\nNetwork Manager\nsudo nmcli connection show\n\n# Create a new static connection on ETH0\nsudo nmcli con add type ethernet con-name &quot;Static Ethernet&quot; ifname eth0 ip4 192.168.1.102/24 gw4 192.168.1.1 ipv4.dns &quot;192.168.1.98, 192.168.1.101&quot;\n\n# Make new connection the default for ETH0\nsudo nmcli connection modify &quot;Old Connection Name&quot; connection.autoconnect no\nsudo nmcli connection modify &quot;Static Ethernet&quot; connection.autoconnect yes\n\nsudo reboot # or, but will loose SSH connection:\nnmcli connection down &quot;Old Connection Name&quot;\nnmcli connection up &quot;Static Ethernet&quot;\n"},"Homelab/OS-and-Virtualization/Proxmox":{"title":"Proxmox","links":["Homelab/OS-and-Virtualization/Linux-Systems-Setup","Homelab/OS-and-Virtualization/Virtualization","Homelab/OS-and-Virtualization/LXC","tags/TODO"],"tags":["TODO"],"content":"Linux Systems Setup\nQuid\nProxmox Virtual Environment (Proxmox VE or PVE) is a Virtualization platform designed for the provisioning of HCI (hyper-converged infrastructure: virtualized computing (a hypervisor) + virtualized storage + virtualized networking in a unified software-defined system).\nProxmox allows deployment and management of virtual machines (with KVM) and containers (with LXC). It is based on a modified Debian LTS kernel. It includes a web-based management interface.\nSource: Wikipedia (edited)\nSetup\nUI Settings\nActivate and do updates:\n\nDatacenters &gt; “proxmox” &gt; Updates &gt; Repos:\n\nAdd download.proxmox.com/debian/pve\nDisable the entreprise ones\n\n\nIn Updates: “Refresh” then “Upgrade”\n\nOnce NAS is available:\n\nMount an SMB share from NAS\nSchedule backups (Datacenter &gt; Backup &gt; Add) with email reports\n\nTODO: Notification System configuration\nTerminal settings\nDo some limited config for the root account, such as installing a couple of programs, setting up aliases and strengthening sshd. See Linux Systems Setup.\nWifi (if needed)\napt update &amp;&amp; apt install wpasupplicant vim\nsystemctl disable wpa_supplicant\nwpa_passphrase SSIDNAME PASSWORD &gt;&gt; /etc/wpa_supplicant/wpa_supplicant.conf\ndmesg | grep wlp # Write down DEVNAME such as wlp6s0\n \nvim /etc/systemd/system/wpa_supplicant.service\n### Add/edit\n[Unit]\nDescription=WPA supplicant\nBefore=network.target\nAfter=dbus.service\nWants=network.target\nIgnoreOnIsolate=true\n \n[Service]\nType=dbus\nBusName=fi.w1.wpa_supplicant1\nExecStart=/sbin/wpa_supplicant -u -s -c /etc/wpa_supplicant/wpa_supplicant.conf -i DEVNAME\nRestart=always\n \n[Install]\nWantedBy=multi-user.target\nAlias=dbus-fi.w1.wpa_supplicant1.service\n###\n \nsystemctl enable wpa_supplicant\n \nvim /etc/network/interfaces\n### Add\nauto DEVNAME\niface DEVNAME inet manual\n    address WISHED_IPADDRESS/24\n    gateway 192.168.1.1\n###\n \nreboot # Or `systemctl restart wpa_supplicant &amp;&amp; systemctl restart networking`\nRef: forum.proxmox.com/threads/howto-proxmox-ve-8-x-x-wifi-with-routed-configuration.147714/\nIOMMU\nShould be enabled by default for AMD processors.\nUseful commands for dealing with (PCIe) disks:\nls -l /sys/block/nvme*/device # /sys/block/nvme1n1/device\n \nlsblk -o NAME,FSTYPE,MOUNTPOINT,SIZE,MODEL\n# nvme1n1                                             465.8G WD Blue SN580 500GB\n# └─nvme1n1p3                  LVM2_member            464.8G\n#   ├─pve-root                 ext4        /             96G\n \nlspci # 01:00.0 Non-Volatile memory controller: Sandisk Corp WD Blue SN580 NVMe SSD (DRAM-less) (rev 01)\n \nudevadm info /dev/nvme5n1\n# P: /devices/pci0000:00/0000:00:01.2/0000:02:00.0/nvme/nvme1/nvme1n1\n# M: nvme1n1\n \nzpool status\nsystemctl status zfs-import-scan.service\nNotes on cloning a VM\nThese things need to be changed on the new VM!\nChange hostname in: /etc/hostname and /etc/hosts\nReset machine ID:\nrm -f /etc/machine-id /var/lib/dbus/machine-id\ndbus-uuidgen --ensure=/etc/machine-id\ndbus-uuidgen --ensure\n\nRegenerate ssh keys:\nregen ssh keys\nsudo rm /etc/ssh/ssh_host_*\nsudo dpkg-reconfigure openssh-server\n"},"Homelab/OS-and-Virtualization/TrueNAS":{"title":"TrueNAS","links":["Homelab/Storage/ZFS","Homelab/OS-and-Virtualization/Proxmox","Homelab/OS-and-Virtualization/Linux-Systems-Setup","Homelab/Storage/Network-Shares","Homelab/Services/Syncthing"],"tags":[],"content":"TrueNAS Scale is a network-attached storage (NAS) product produced by iXsystems. Based on the Open ZFS file system, it runs on Linux and is compatible with virtualization hosts such as Proxmox.\nNetworking protocols supported by TrueNAS include SMB, NFS, iSCSI, rsync and SFTP.\nSource: Wikipedia\nSetup\nVM Installation\n\nCreate VM settings:\n\nMachine = q35, BIOS = Default\nDisk = 32GB, CPU cores = 12, CPU type = x86-64-v4, RAM = 32768\n\n\nSetup PCIe passthrough for the non-boot SDDs\n\nlsblk -o NAME,FSTYPE,MOUNTPOINT,SIZE,MODEL to identify proxmox’s boot drive, e.g. “nvme1n1”\nudevadm info /dev/nvme1n1 to identify pci id, e.g “ID_PATH=pci-0000:02:00.0-nvme-1”\nFor all others, repeat:\n\nProxmox: Hardware &gt; Add &gt; PCI Device\nRaw Device &gt; Device = 0000:01:00.0, All Functions\nAdd\n\n\n\n\nProxmox: Options:\n\nStart at boot: Yes\nStart order: order=1\n\n\nStart VM\nUI at http://see-address-in-proxmox-console\n\nConfig Network &amp; System\nNetwork\n\nInterfaces, Edit: Disable DHCP, add alias 192.168.1.100/24\nAdd DNS server and gateway (necessary when dhcp disabled)\n\nSystem\n\nServices: Enable (NFS), SMART, SMB, SSH\nDisable Password Auth for SSH\n\nCreate Pools &amp; Datasets\nStorage: Create pool\n\nDataset: RAIDZ1 layout\nNote: If using all drives, there can only be one pool\nDon’t enable encryption (if at least some of the datasets won’t be encrypted)\nSkip other optional steps (see youtu.be/3T5wBZOm4hY for details)\n\nDatasets: Add dataset\n\nsystem (leave unencrypted)\n\nusers\n\n\n\nUser Accounts\nCredentials: Users: Add\n\nUSER, UID: 1000\nHome dir: /mnt/main-pool/users, Perm rwx-----, “Create Home Directory”\nUpload main id_rsa.pub (and paste e.g. dockerhost’s id_rsa.pub)\nShell: bash, “Allow all sudo commands”\n\nTest user by ssh logging in. Create bash aliases (Linux Systems Setup).\nCreate another “sambaguest” user, without ssh key and without sudo permission.\nCreate other Shares and Datasets\nSee Network Shares for technical details\nExample:\n\nAdd Apps\nSyncthing\nAdd alerts\n\nAdd an email address to at least one admin user\nSystem &gt; general settings &gt; email &gt; settings\nSystem &gt; alert settings &gt; alert services &gt; edit email / add telegram\n"},"Homelab/OS-and-Virtualization/Virtualization":{"title":"Virtualization","links":["Homelab/OS-and-Virtualization/Proxmox","Homelab/OS-and-Virtualization/LXC","Homelab/OS-and-Virtualization/Docker"],"tags":[],"content":"Hardware virtualization (VMs)\nProxmox is currently used as the VM hypervisor.\nOS virtualization (containers)\nLXC or Docker\nDifferences between VMs and Containers\nVMs provide full hardware virtualization. A full, independent, isolated OS runs in the VM. As far as the OS is concerned, it interacts with a real computer (BIOS, CPU, Storage, Keyboard, etc.), even though most of these components are virtual ones managed by the host’s hypervisor (vCPUs, etc.).\nContainers only provide an isolated environment for applications (as opposed to for an OS). Importantly, the kernel used by the containers is that of the host’s. This makes containers much lighter-weight than VMs.\nContainers are therefore usually faster (less abstraction) but provide less isolation (kernel sharing).\nDocker, LXC or VM for a new service?\n\nUse Docker when possible\nIf not, consider LXC first\n\nIn theory it can offer: more “isolation” (behaves more like a full VM, no Docker net integration, etc.), hardware passthrough capabilities, its own IP directly on LAN.\nIn practice, the few times I used them, it was a pain and it always ended up being better to switch to either a Docker or a VM.\nRunning them without privileges makes them hard to use and less useful but running them privileged is dangerous.\nOne definite use case is to test/play with OSes (the few that have an LXC template…) without having to go through the relatively long installation process.\n\n\n\n\nOtherwise, create a VM\n\nCPU and RAM allocation\nFor CPU cores in Proxmox, you don’t need to match the cumulative number of virtual cores (vCPUs) assigned to VMs with the physical cores available on your host system. Proxmox uses CPU time scheduling to share the available physical cores among VMs. You can actually “overcommit” CPU resources, meaning you can assign more virtual cores to your VMs than you have physical cores.\nHowever, there are some important considerations:\n\nWhile you can overcommit, assigning too many vCPUs can lead to performance degradation when VMs compete for CPU time\nA good starting point is staying within 1:1 to 2:1 ratio (virtual to physical cores) for production environments\nThe optimal ratio depends on your workload patterns and whether VMs are consistently CPU-intensive\n\nFor RAM, the situation is different:\n\nRAM is a finite resource that cannot be as flexibly shared between VMs\nYou generally should not allocate more RAM to VMs than physically available on the host (minus what the host OS needs)\nWhile some memory overcommitment is possible using features like KSM (Kernel Samepage Merging) and ballooning, it’s risky and can severely impact performance if VMs actually try to use all their allocated memory\nA safe approach is to leave about 1-2GB for the Proxmox host system and only allocate the remaining RAM to VMs\n\nSource: Claude.ai\nRAM\nVM memory ballooning:\n\nNot recommended for TrueNAS\nFor others, may use as “extra memory”\nFor example, set total RAM = 1.3 * minimum RAM\n\nCheck usage:\nfree -h # general\narc_summary # ZFS details\ndocker stats --no-stream # containers\nLimit available memory for a Docker container to 512MB:\n    mem_limit: 512m\n    memswap_limit: 512m\nInvestigate:\njournalctl --since &quot;24 hours ago&quot; | grep -i &quot;memory\\|oom\\|killed&quot;"},"Homelab/Security/Homelab-Security":{"title":"Homelab Security","links":["tags/TODO","Homelab/Internet-Infrastructure/Reverse-Proxy","Homelab/Internet-Infrastructure/Cloudflare","Homelab/OS-and-Virtualization/Kali-Linux","Homelab/Security/Security---Cryptography","Homelab/Security/fail2ban"],"tags":["TODO"],"content":"TODO\nCf.\n\nReverse Proxy\nCloudflare\nKali Linux\nSecurity - Cryptography\nfail2ban\n"},"Homelab/Security/Security---Cryptography":{"title":"Security - Cryptography","links":[],"tags":[],"content":"Crypto Algorithms\nEd25519 and difference with RSA\nEd25519 is a modern digital signature scheme using elliptic curve cryptography (specifically, a twisted Edwards curve). It’s named after the curve it uses (Edwards curve 25519). RSA is an older public-key cryptosystem based on the mathematical properties of large prime numbers.\nKey differences:\n\nSecurity and Key Size: Ed25519 provides equivalent security to RSA with much smaller key sizes. An Ed25519 key is just 32 bytes (256 bits) while achieving security equivalent to a 3072-bit RSA key.\nPerformance: Ed25519 is significantly faster than RSA, especially for signing operations. It was designed with modern hardware in mind and includes protections against timing attacks.\nImplementation: Ed25519 is simpler to implement correctly and securely. RSA implementations need careful attention to padding schemes (like PKCS#1 v2.1) and are more prone to implementation mistakes.\nMathematical Basis:\n\nRSA relies on the difficulty of factoring large numbers (the factoring problem)\nEd25519 relies on the discrete logarithm problem over elliptic curves\n\n\nUsage: While RSA can be used for both encryption and signatures, Ed25519 is specifically designed for digital signatures. For encryption, a related curve (Curve25519) is used in the X25519 key exchange.\n\nEd25519 is increasingly becoming the preferred choice for new systems, especially in contexts like SSH keys and cryptocurrency addresses, due to its combination of security, performance, and ease of implementation.\nSource: Claude\nNote:\n\nCurve25519 is used for key exchange/encryption (e.g. by WireGuard)\nEd25519 is used for digital signatures\n\nSymmetric VS Asymmetric encryption for data transfer\nCompared to asymmetric, symmetric encryption is:\n- Much faster (often 100-1000x)\n- Can encrypt unlimited data\n- Requires fewer CPU resources. Hardware acceleration available for algorithms like AES\nHence the use of symmetric encryption by even modern protocols such as Wireguard:\n\nUse public key cryptography to authenticate and securely exchange a session key\nThen use that session key with symmetric encryption for the actual data transfer\n\nWireguard’s optional pre-shared key (PSK) is also symmetric.\nSymmetric encryption is more quantum-resistant. All current elliptic curve cryptography is theoretically vulnerable to Shor’s algorithm, just like RSA. The main threat to symmetric encryption comes from Grover’s algorithm, which can effectively reduce the security of a symmetric key by half. 256 bits is considered quantum-safe."},"Homelab/Security/fail2ban":{"title":"fail2ban","links":["Homelab/Services/Nginx-Proxy-Manager-(NPM)"],"tags":[],"content":"Security tool that monitors log files for suspicious activity (like repeated failed login attempts) and automatically blocks offending IP addresses for a specified period of time. It can monitor logs from various services like SSH and web servers, making it an effective defense against brute force attacks.\nSetup\nWe setup fail2ban on Dockerhost to\n\nDetect suspicious ssh behaviors (not too relevant as ssh isn’t exposed to the WAN, but this is enabled by default on Debian so we might as well configure it)\n\nBans through iptables\n\n\nDetect suspicious web behavior through Nginx Proxy Manager (NPM)\n\nBans at the Cloudflare level, through their API (iptables would be useful as public traffic is only only going through Docker network layers)\n\n\nAll bans are reported to Telegram\n\nFail2ban can similarly be setup on other hosts for SSH/etc as needed. Note: TrueNAS has its own failure reporting system (System &gt; Alert settings &gt; System).\nSetup NPM\nThe Cloudfare connecting IP (header CF-Connecting-IP) needs to be saved in the logs.\nThis just adds “[CF-conn-IP $http_cf_connecting_ip]” to the default NPM log format:\nsudo -u dockeruser tee -a /srv/docker/volumes/npm/data/nginx/custom/http_top.conf\n\nlog_format default_plus_cf &#039;[$time_local] $upstream_cache_status $upstream_status $status - $request_method $scheme $host &quot;$request_uri&quot; [Client $remote_addr] [CF-conn-IP $http_cf_connecting_ip] [Length $body_bytes_sent] [Gzip $gzip_ratio] [Sent-to $server] &quot;$http_user_agent&quot; &quot;$http_referer&quot;&#039;;\n\nThen, in NPM’s UI &gt; Proxy hosts &gt; “Edit” relevant hosts &gt; Advanced, add:\nlocation / {\n    access_log /data/logs/proxy-host-X_access.log default_plus_cf;\n}\n\nwhere X is the host number.\nSetup Cloudflare\nWe need a Firewall Access Rules token for the cloudflare-firewall action.\nGo to CF Dashboard &gt; My Profile &gt; API Tokens &gt; Create Token &gt; Create Custom Token:\n\nToken name: Fail2Ban\nPermissions: Account, Account Firewall Access Rules, Edit\nOther fields can be left as default or as applicable.\nSummary &gt; Create\n\nSetup Telegram\nFor the telegram-notif action.\nSee online how to get the Bot Token and the Chat Id.\nSetup Fail2Ban\nsudo apt update &amp;&amp; sodo apt install fail2ban jq\n/etc/fail2ban/jail.local\n[DEFAULT]\nbantime = 2h\nfindtime = 10m\nmaxretry = 3\naction = cloudflare-firewall\n         telegram-notif\n# Ignore all direct wireguard-to-npm access\nignoreip = 127.0.0.1/32 192.168.1.0/24 172.20.0.3/32\n\n# sshd is activated by default in jail.d/defaults-debian.conf\n[sshd]\nbackend = systemd\naction = iptables\n         telegram-notif\n\n# NPM 404 errors (potential scanning)\n[npm-404]\nenabled = true\nlogpath = /srv/docker/volumes/npm/data/logs/proxy-host-*_access.log\nfilter = npm-404\n# Less strict for 404s\nmaxretry = 10\n\n# HTTP forbidden access\n[npm-403]\nenabled = true\nlogpath = /srv/docker/volumes/npm/data/logs/proxy-host-*_access.log\nfilter = npm-403\n\n# NPM forbidden access\n[npm-forbidden]\nenabled = true\nlogpath = /srv/docker/volumes/npm/data/logs/proxy-host-*_error.log\nfilter = npm-forbidden\n\n# NPM protocol errors (SSL etc)\n[npm-protocol]\nenabled = true\nlogpath = /srv/docker/volumes/npm/data/logs/fallback_access.log\nfilter = npm-protocol\n\n/etc/fail2ban/filter.d/npm-404.conf\n# For NPM&#039;s 404 errors in proxy-host-X_access.log\n[Definition]\n# If CF-conn-IP is present and not &quot;-&quot;, use that, otherwise use Client IP\nfailregex =  404 - .* \\[Client [^\\]]+\\] \\[CF-conn-IP &lt;HOST&gt;\\]\n             404 - .* \\[Client &lt;HOST&gt;\\] (\\[CF-conn-IP -\\]|\\[Length)\ndatepattern = \\[b/H:S \\+0100\\]\n\n/etc/fail2ban/filter.d/npm-403.conf\n# For NPM&#039;s 403 errors in proxy-host-X_access.log\n[Definition]\n# If CF-conn-IP is present and not &quot;-&quot;, use that, otherwise use Client IP\nfailregex =  403 - .* \\[Client [^\\]]+\\] \\[CF-conn-IP &lt;HOST&gt;\\]\n             403 - .* \\[Client &lt;HOST&gt;\\] (\\[CF-conn-IP -\\]|\\[Length)\ndatepattern = \\[b/H:S \\+0100\\]\n\n/etc/fail2ban/filter.d/npm-forbidden.conf\n# For NPM&#039;s &quot;access forbidden by rule, client: x.x.x.x&quot; in proxy-host-X_error.log\n[Definition]\nfailregex = access forbidden by rule, client: &lt;HOST&gt;,\ndatepattern = m/H:S\n\n/etc/fail2ban/filter.d/npm-protocol.conf:\n# For 400/444/maybe-others errors from NPM&#039;s fallback_access.log\n[Definition]\nfailregex = \\] 4[0-9][0-9] - .* \\[Client [^\\]]+\\] \\[CF-conn-IP &lt;HOST&gt;\\]\n            \\] 4[0-9][0-9] - .* \\[Client &lt;HOST&gt;\\] (\\[CF-conn-IP -\\]|\\[Length)\ndatepattern = \\[b/H:S \\+0100\\]\n\n/etc/fail2ban/action.d/telegram-notif.conf: (chmod 600)\n[Definition]\nactionban = curl -X POST api.telegram.org/bot&lt;token&gt;/sendMessage \\\n            -d chat_id=&lt;chat_id&gt; \\\n            -d parse_mode=HTML \\\n            -d &quot;text=🚫 Banned &lt;ip&gt; to jail &#039;&lt;name&gt;&#039; -- &lt;matches&gt;&quot;\n\nactionunban = curl -X POST api.telegram.org/bot&lt;token&gt;/sendMessage \\\n              -d chat_id=&lt;chat_id&gt; \\\n              -d &quot;text=✅ Unbanned &lt;ip&gt; from jail &#039;&lt;name&gt;&#039;&quot;\n\n[Init]\ntoken = TELEGRAM_TOKEN\nchat_id = TELEGRAM_CHATID\n\n/etc/fail2ban/action.d/cloudflare-firewall.conf: (chmod 600)\n[Definition]\nactionban = curl -s -X POST &lt;_cf_headers&gt; &lt;_cf_url&gt; \\\n                -d &#039;{&quot;mode&quot;:&quot;block&quot;,&quot;configuration&quot;:{&quot;target&quot;:&quot;ip&quot;,&quot;value&quot;:&quot;&lt;ip&gt;&quot;},&quot;notes&quot;:&quot;Fail2Ban - jail &lt;name&gt;&quot;}&#039;\n\nactionunban = id=$(curl -s &lt;_cf_headers&gt; &quot;&lt;_cf_url&gt;?mode=block&amp;configuration_target=ip&amp;configuration_value=&lt;ip&gt;&quot; \\\n                  | jq -r .result[0].id)\n              if [ &quot;$id&quot; = &quot;null&quot; ]; then echo &quot;&lt;name&gt;: id for &lt;ip&gt; cannot be found&quot;; exit 0; fi;\n              curl -s -o /dev/null -X DELETE &lt;_cf_headers&gt; &quot;&lt;_cf_url&gt;/$id&quot;\n\n[Init]\n_cf_url = &quot;api.cloudflare.com/client/v4/user/firewall/access_rules/rules&quot;\n_cf_headers = -H &quot;Authorization: Bearer CF_FIREWALL_API_TOKEN&quot; -H &quot;Content-Type: application/json&quot;\n\nReplace TELEGRAM_TOKEN, TELEGRAM_CHATID and CF_FIREWALL_API_TOKEN above.\nDouble-check timezone in datepattern expressions are correct.\nIf local IPs should be ignored at the filter level instead of at the jail one (jail.local), use for example the following expression is npm-404.conf, etc:\nignoreregex = \\[Client (?:127\\.0\\.0\\.1|192\\.168\\.1\\.\\d+|172\\.20\\.0\\.3)\\]\nUseful commands\nRestart and see startup logs:\nsudo systemctl restart fail2ban &amp;&amp; sleep 2 &amp;&amp; sudo systemctl status fail2ban | cat\nManual ban/unban an IP for filter sshd (will trigger associated actions):\nsudo fail2ban-client set sshd banip 66.66.66.66\nsudo fail2ban-client set sshd unbanip 66.66.66.66\n\nParse a (test or real) log file with filter npm-404 and see failed/ignored/missed lines:\nfail2ban-regex /tmp/test-404.log /etc/fail2ban/filter.d/npm-404.conf\nTests\nVerify IP bans work in Cloudflare\nGo to CF Dashboard &gt; click on a domain &gt; Security &gt; WAF &gt; Tools &gt; IP Access Rules.\nsudo fail2ban-client set npm-404 banip 66.66.66.66 for example should create an entry “66.66.66.66 / Fail2Ban - jail npm-404”.\nLog files used to test NPM rules with fail2ban-regex\nFile: /tmp/test-403.log\n[31/Dec/2024:13:26:07 +0000] - - 403 - GET https transmission.one137.dev &quot;/favicon.ico&quot; [Client 172.18.0.1] [Length 111] [Gzip 1.35] [Sent-to ct-wire\nguard-client] &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 18_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.0 Mobile/15E148 Safari/604.\n1&quot; &quot;-&quot;\n[06/Jan/2025:09:20:30 +0100] - - 403 - HEAD https one137.dev &quot;/test&quot; [Client 192.168.1.66] [CF-conn-IP -] [Length 0] [Gzip -] [Sent-to STATIC_FILES]\n&quot;curl/8.7.1&quot; &quot;-&quot;\n[06/Jan/2025:09:22:03 +0100] - - 403 - GET https one137.dev &quot;/test&quot; [Client 172.21.0.2] [CF-conn-IP 197.130.148.156] [Length 111] [Gzip 1.35] [Sent-t\no STATIC_FILES] &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 18_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.0 Mobile/15E148 Safari/60\n4.1&quot; &quot;-&quot;\n\nFile: /tmp/test-404.log\n[04/Jan/2025:21:27:41 +0000] - - 404 - GET https one137.dev &quot;/abc&quot; [Client 172.21.0.2] [CF-conn-IP 197.130.148.156] [Length 111] [Gzip 1.35] [Sent-to\n STATIC_FILES] &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 18_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.0 Mobile/15E148 Safari/604\n.1&quot; &quot;-&quot;\n[02/Jan/2025:22:46:04 +0000] - 404 404 - GET https portainer.one137.dev &quot;/api/endpoints/2&quot; [Client 192.168.1.66] [Length 168] [Gzip -] [Sent-to ct-po\nrtainer] &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36&quot; &quot;https://portainer.o\nne137.dev/&quot;\n[04/Jan/2025:21:25:57 +0000] - - 404 - GET https one137.dev &quot;/abc&quot; [Client 192.168.1.66] [CF-conn-IP -] [Length 172] [Gzip 3.21] [Sent-to STATIC_FILE\nS] &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36&quot; &quot;-&quot;\n\nFile: /tmp/test-forbidden.log\n2025/01/02 22:46:54 [error] 254#254: *24053 access forbidden by rule, client: 172.21.0.2, server: one137.dev, request: &quot;GET / HTTP/2.0&quot;, host: &quot;one13\n7.dev&quot;\n2025/01/02 22:46:54 [error] 254#254: *24053 access forbidden by rule, client: 172.20.0.3, server: one137.dev, request: &quot;GET / HTTP/2.0&quot;, host: &quot;one13\n7.dev&quot;\n\nFile: /tmp/test-protocol.log\n[04/Jan/2025:23:40:05 +0100] 400 - - http localhost &quot;-&quot; [Client 190.168.1.66] [Length 154] [Gzip -] &quot;-&quot; &quot;-&quot;\n[04/Jan/2025:23:40:05 +0100] 400 - - http localhost &quot;-&quot; [Client 190.168.1.66] [Length 154] [Gzip -] &quot;-&quot; &quot;-&quot;\n[04/Jan/2025:23:39:57 +0100] 444 - GET https localhost &quot;/&quot; [Client 192.168.1.66] [Length 0] [Gzip -] &quot;-&quot; &quot;-&quot;\n[04/Jan/2025:23:39:57 +0100] 444 - GET https localhost &quot;/&quot; [Client 192.168.1.66] [Length 0] [Gzip -] &quot;-&quot; &quot;-&quot;\n\nGenerate 403 errors\nIf no real 403 route is configured, add in an NPM proxy host:\nlocation /test-403 {\n  return 403;\n  access_log /data/logs/proxy-host-1_access.log default_plus_cf;\n}\n\nGenerate protocol errors\n400: Bad Request (malformed requests, invalid TLS) errors can be generated using\nopenssl s_client -connect one137.dev:443 -no_tls1_2 -no_tls1_3 -quiet\n\nC03DC746F87F0000:error:0A0000BF:SSL routines:tls_setup_handshake:no protocols available:ssl/statem/statem_lib.c:153\n\n444: Connection Closed (suspicious TLS behavior) errors with\necho -n &quot;GET / HTTP/1.0\\r\\n\\r\\n&quot; | openssl s_client -connect one137.dev:443 -quiet\n\nC03DC746F87F0000:error:0A000126:SSL routines::unexpected eof while reading:ssl/record/rec_layer_s3.c:693\n"},"Homelab/Services/Cloudflared":{"title":"Cloudflared","links":["tags/TODO"],"tags":["TODO"],"content":"TODO\nSetup\nCloudflare\n\nAccount &gt; Zero Trust &gt; Networks &gt; Tunnels\nCreate a tunnel &gt; Cloudflared &gt; Choose name &gt; Docker &gt; Copy &amp; save token &gt; Next\nAdd public hostname\n\nhostname: e.g. transmission.one137.dev/transmission/web\nService: e.g. https://ct-transmission (docker container names ok)\nTLS\n\nOrigin Server Name: transmission.one137.dev (probably)\nHTTP2 connection: On\n\n\n\n\n\nConnector (Docker)\nservices:\n  cloudflared:\n    container_name: ct-cloudflared\n    image: cloudflare/cloudflared:latest\n    command: tunnel --no-autoupdate run --token ${TOKEN}\n    restart: unless-stopped\nAdd ct-npm to 50-couldflared_default network"},"Homelab/Services/DNSMasq":{"title":"DNSMasq","links":["tags/TODO","Homelab/Services/Wireguard"],"tags":["TODO"],"content":"Dnsmasq provides DNS, DHCP, router advertisement and network boot for small networks infrastrutures.\nThe DNS subsystem provides a local DNS server for the network, with forwarding of all query types to upstream recursive DNS servers and caching of common record types (A, AAAA, CNAME, etc).\nWhy\nBecause *.one137.dev is mapped to dockerhost, when a Wireguard client or any other Docker container requests :443 on one of these domains, the route is as follow:\n\nClient: 10.8.0.2 on utun6\nwg-easy: 10.8.0.1 on wg0\nwg-easy: 172.20.0.3 on eth0@if68 (40-wireguard-easy_default)\ndockerhost: 172.20.0.1 on br-556c30b41c98 (40-wireguard-easy_default)\ndockerhost: 192.168.1.101 on enp6s18\ndockerhost: 172.18.0.1 on br-58d3a89e5f29 (30-pihole_default)\nct-npm: 172.18.0.3 on eth0 (30-pihole_default)\n\nAnd 172.18.0.1 appears as the client in NPM’s logs. ( TODO  That being said, I don’t understand why traffic coming from say 192.168.1.66 doesn’t also show up as 172.18.0.1, as steps 5-7 should be the same).\nThe problem with that is\n\nIt’s impossible to distinguish traffic coming from Wireguard, because traffic coming from any Docker container is tagged as coming from 172.18.0.1. For security (in case a container gets compromised), requests from containers to *.one137.dev (other containers, proxmox, etc.) should be blocked, as there’s no reason they’d talk.\nIt’s inelegant. ct-npm is also present on 40-wireguard-easy_default at 172.20.0.4, so the whole roundtrip to dockerhost’s physical interface (steps 4-6) is not needed. 172.20.0.3 can talk to 172.20.0.4 directly.\n\nSetup\n\n\n                  \n                  Warning\n                  \n                \n\nThere is almost a circular dependency: DNSMasq &gt;(needs IP of)&gt; NPM &gt;(needs IP of)&gt; Wireguard &gt;(needs subnet of)&gt; 40-wireguard-easy_default.\nThese dependencies make it complicated to deploy cleanly. And if the IPs of these 2 containers (or the network subnet) change, they’ll need to be updated manually as per instructions below.\n40-wireguard-easy_default could be configured with static IPs, but that also makes the setup slightly more complex.\nOverall the setup might be creating more problem than solutions as the original issue isn’t significant, but it’s a fun experiment.\n\n\nThere is no official nor linuxserver Docker image for dnsmasq. 4km3’s image seems currently well maintained and very minimal (it’s just an alpine-based entrypoint).\nAdd this to stack Wireguard Server:\nservices:\n  dnsmasq:\n    image: 4km3/dnsmasq\n    container_name: ct-dnsmasq-wireguard\n    cap_add:\n      - NET_ADMIN\n    volumes:\n      - /srv/docker/volumes/dnsmasq-wireguard/dnsmasq.conf:/etc/dnsmasq.conf\n    restart: unless-stopped\n\nGet following IPs on network 40-wireguard-easy_default:\n\nNPM’s IP: docker exec ct-dnsmasq-wireguard ping -c 1 ct-npm | head -2\nDNSMarq’s IP: docker exec ct-dnsmasq-wireguard ip a | grep 172\n\nCreate /srv/docker/volumes/dnsmasq-wireguard/dnsmasq.conf:\nlog-facility=- # logs to stderr for docker logs\naddress=/one137.dev/172.20.0.x # NPM&#039;s IP on 40-wireguard-easy_default\n\n, set the proper NPM IP then restart DNSMasq.\nWireguard-easy’s default DNS WG_DEFAULT_DNS must then be set to DNSMarq’s IP and restarted.\nFinally, NPM’s proxy for one137.dev must allow 40-wireguard-easy_default’s range in its advanced settings: allow 172.20.0.0/29;."},"Homelab/Services/Diun":{"title":"Diun","links":[],"tags":[],"content":"Docker Image Update Notifier is a CLI application to receive notifications when a Docker image is updated on a Docker registry.\n\nAllow watching a Docker repository and report new tags\nInclude and exclude filters with regular expression for tags\nInternal cron implementation\nDocker, Kubernetes, Swarm, Nomad, Dockerfile and File providers available\n\ncrazymax.dev/diun/\nSetup\nservices:\n  diun:\n    image: crazymax/diun:latest\n    container_name: ct-diun\n    command: serve\n    volumes:\n      - /srv/docker/volumes/diun/data:/data\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n    environment:\n      - TZ=Europe/Zurich\n      - LOG_LEVEL=info # One of panic, fatal, error, warn, [info], debug, trace\n      - DIUN_WATCH_SCHEDULE=0 21 * * *\n      - DIUN_PROVIDERS_DOCKER=true\n      - DIUN_PROVIDERS_DOCKER_WATCHBYDEFAULT=true\n      - DIUN_NOTIF_TELEGRAM_TOKEN=${TELEGRAM_TOKEN}\n      - DIUN_NOTIF_TELEGRAM_CHATIDS=${TELEGRAM_CHATID}\n      - &#039;DIUN_NOTIF_TELEGRAM_TEMPLATEBODY=*Diun*: {{ if .Entry.Image.HubLink }}[{{ .Entry.Image.Path }}:{{ .Entry.Image.Tag }}]({{ .Entry.Image.HubLink }}){{ else }}{{ .Entry.Image }}{{ end }} has been {{ if (eq .Entry.Status &quot;new&quot;) }}newly added{{ else }}updated{{ end }} on {{ .Entry.Manifest.Created.Format &quot;2006-01-02 Mon&quot; }}.&#039;\n    restart: unless-stopped\nEnv vars set in the doc examples at their default value have been omitted, except LOG_LEVEL.\nTest notifications\ndocker exec ct-diun diun notif test\nExample\n\nDiun: docker.io/diun/testnotif:latest has been newly added on 2020-03-26 Thu.\n\nSee crazymax.dev/diun/faq/#notification-template to tweak message body."},"Homelab/Services/Healthchecks":{"title":"Healthchecks","links":["Homelab/Services/Uptime-Kuma"],"tags":[],"content":"healthchecks.io\nGet notified when a scheduled task doesn’t run (on time):\n\nSend an HTTP GET to healthchecks.io every time the job run\nIf the job does’t ping on time, get alerted by Healthchecks.io.\n\nSetup\n\nCreate a UUID at healthchecks.io\nPing (HTTP GET request, e.g.) hc-ping.com/(UUID) every few minutes, e.g. from Uptime-Kuma\n\nBy setting Period = 5 min &amp; Grace = 7 min, two consecutive pings within 10 minutes must fail to get a notification (12 min after the lat successful ping)\n\n\nTelegram notifs (disable email)\n\nAdd bot HealthchecksBot to a group\n/start@HealthchecksBot in that group\nClick link and login\n\n\n"},"Homelab/Services/Homelab-Networking":{"title":"Homelab Networking","links":["Homelab/Services/Services-and-network-layout.canvas","Homelab/Services/Nginx-Proxy-Manager-(NPM)","Homelab/Services/Wireguard"],"tags":[],"content":"See Services and network layout.\nUseful commands\nip address\nip route\n\nIn case of subnet conflict, explicitly route IPs 192.168.1.96/28 (16 IPs, 96-111) through the VPN interface:\nsudo route add -net 192.168.1.96 -netmask 255.255.255.240 -interface utun4\nFlush DNS chache:\nsudo dscacheutil -flushcache; sudo killall -HUP mDNSResponder\nList all tcp/udp listening ports and their proceses:\nsudo ss -tulpn or netstat if ss is unavailable\nDisplay the kernel routing table:\nnetstat -r\nDocker Networking\nUsing a star network, where each container is isolated from one another but all that need incoming connections are connected to NPM.\nContainers that need outgoing VPN connection directly share ct-wireguard-client’s container network.\nOutdated example:\ngraph TD\nct-ddclient --&gt; |172.18.0.2| ddclient_default[&quot;ddclient_default\\n(Gateway: 172.18.0.1)&quot;]\n\nmongodb_internal[&quot;mongodb_internal\\n(Gateway: 172.25.0.1)&quot;] --&gt; |172.25.0.3| ct-npm\nct-mongo --&gt; |172.25.0.2| mongodb_internal\n\nwg-client_default[&quot;wg-client_default\\n(Gateway: 172.21.0.1)&quot;] --&gt; |172.21.0.3| ct-npm\nct-wg-client --&gt; |172.21.0.2| wg-client_default\nct-transmission --&gt; ct-wg-client\n\nSpeeds tests\nfio writes\nfio tests from Debian:\n\nfio --name=write_test --size=1G --bs=4k --rw=write --direct=1 --directory=...\n\n/home/USER/fio: 100MB/s\n/mnt/nas-video/fio: 43MB/s\n/mnt/nas-xfs-zvol/fio: 35 MB/s\n\n\nno --direct flag:\n\nAll up to 3’600 MB/s\n\n\n\niperf3 transfer\niperf3 tests:\n\nDebian - Proxmox:  33.8 Gbps\nmacOS - Debian:\n\n942 Mbps RJ-45\n776 Mbps Wifi living room\n82 Mbps Wifi office\n\n\n\nInternet connexion (speedtest.net)\n\nWifi: 95 MB/s (760 Mbps)\nrj45: 118 MB/s (940 Mbps)\n\nPlain file transfer\nTransfer times of movie.mkv, 2.6GB, 2765358436 bytes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom/TomacOS WifimacOS rj45ProxmoxDebianTNAS SSHTNAS SMBTNAS SMB Un-encryptTNAS NFSmacOS Wifi1s–53s52s52s34smacOS rj45––24s24s33s24sProxmox29s24s1s3s10s9s24sDebian29s24s3s1s3s / 10s9s2sTNAS SSH29s24s61s / 20s / 3s61s / 3s0sTNAS SMB27s24s15s / 3s16s / 1s–TNAS SMB Un-encrypt2s–TNAS NFS32s / 2s–\n\n1s = 2’637 MB/s\n3s =   879 MB/s\n9s =   293 MB/s (2.3 Gbps)\n15s =  176 MB/s (1.4 Gbps)\n24s =  110 MB/s (0.9 Gbps) ⇐ rj45 limit\n27s =   98 MB/s (0.8 Gbps) ⇐ Wifi 5/ac limit\n34s =   78 MB/s\n52s =   51 MB/s\n\nSummary\nmacOS\n\nRJ-45\n\nReads and writes always optimal (close to 1Gbps)\nExcept writes to TrueNAS by SSH (SMB no prob)\n\n\nWifi\n\nReads mostly optimal (SMB best, ~780 Mbps)\nWrites are ok on SMB, 25% slower than reads\nWrites are BAD on SSH, 80% slower than reads\nIntra VMs &amp; Non-encrypted TrueNAS\n\n\nReads/writes are extremely fast (7 Gbps)\nTrueNAS Reads/writes possibly instantaneous (12+ Gbps) even when not cached?\nEncrypted TrueNAS\nReads can be as slow as 1.5 Gbps\nCached read are instantaneous (12 Gbps)\nWrites are average (2.3Gbps), both SSH/SMB\nWith 8 vCPU\n\nReads 33% faster (16s → 11s)\nWrites 40% faster (9 → 5.3s)\n\n\nWith 12 vCPUs instead of 4\n\nReads 50% faster (8s)\nWrite 55% faster (3.9s)\n\n\nAdding RAM doesn’t change speeds (as expected)\n"},"Homelab/Services/Homelab-Services":{"title":"Homelab Services","links":["Homelab/Services/Pi-Hole","Homelab/Services/Wireguard","Homelab/Services/DNSMasq","Homelab/Services/Cloudflared","Homelab/Services/ddclient","Homelab/Services/Jellyfin","Homelab/Services/Mailrise","Homelab/Services/MongoDB","Homelab/Services/Transmission","Homelab/Services/Diun","Homelab/Services/Uptime-Kuma","Homelab/Services/Nginx-Proxy-Manager-(NPM)","Homelab/Services/Web-Server","Homelab/Services/Portainer","Homelab/Services/Syncthing","Homelab/Security/fail2ban","Homelab/Services/Services-and-network-layout.canvas"],"tags":[],"content":"Current list of services hosted\nHosted on Docker unless specified.\n\nPi-Hole (x2, once on Bare)\nWireguard (server and client)\nDNSMasq (for Wireguard server)\nCloudflared\nddclient\nJellyfin\nMailrise\nMongoDB\nTransmission\nDiun\nUptime-Kuma\nNginx Proxy Manager (NPM) including Web Server\nPortainer\nSyncthing (on TrueNAS)\nfail2ban (on Bare)\n\nProgrammable config\nname, host, proxy, protocol\n \nrouter, 192.168.1.1, http://router:80, -\npihole1, 192.168.1.98, http://pihole1:80, -\nproxmox, 192.168.1.99, https://proxmox:8006, WS\ntruenas, 192.168.1.100, http://truenas:80, WS\ndockerhost, 192.168.1.101, -\n \njellyfin, dockerhost, http://ct-jellyfin:8096, WS\nnpm, dockerhost, http://ct-npm:81, -\npihole2, dockerhost, http://ct-pihole:80, -\nportainer, dockerhost, https://ct-portainer:9443, -\nsyncthing, dockerhost, https://truenas:20910, -\ntransmission, dockerhost, http://ct-wireguard-client:9091, -\nuptime-kuma, dockerhost, http://ct-uptime-kuma:3001, -\nwireguard-easy, dockerhost, http://wireguard-easy:51821, -\n \nmailrise, dockerhost, stream://ct-mailrise:8025, TCP\nmongodb, dockerhost, stream://ct-mongodb:27017, TCP\nwireguard-easy, dockerhost, stream://wireguard-easy:51820, UDP\n \ncloudflared, dockerhost, -, -\nddclient, dockerhost, -, -\ndiun, dockerhost, -, -\ndnsmasq-wireguard, dockerhost, -, -\nwireguard-client, dockerhost, -, -\n \none137, dockerhost, http://STATIC_FILES:1, -\nSee Services and network layout (not public).\nRecap / Steps to add a new Docker service (MongoDB example)\n\nDeploy service through a new Portainer stack, and update NPM’s stack\n\nDon’t expose any ports\nName the stack and container as per convention, e.g. 50-mongodb and ct-mongodb\nConfigure volumes and networks as needed\nStart the stack\nIn the NPM stack:\n\nExpose the new container’s non-web ports, if any\nAdd the new stack’s network to NPM’s networks\nRestart NPM\n\n\n\n\nAdd proxied address in NPM\n\nFor http(s) services:\n\nProxy host\ncontainer’s name as the destination (ct-transmission:9091)\na .one137.dev cert\nthe LAN+Wireguard access\n\n\nFor others:\n\nStream host\ncontainer’s name as the destination (ct-mongo:27017)\n\n\n\n\nEnjoy (e.g. mongosh mongodb://*:*@mongodb.one137.dev:27017)\nAdd service uptime monitoring to Uptime-Kuma\n"},"Homelab/Services/Jellyfin":{"title":"Jellyfin","links":["Homelab/Storage/Network-Shares"],"tags":[],"content":"In Docker\nservices:\n  jellyfin:\n    image: lscr.io/linuxserver/jellyfin:latest\n    container_name: ct-jellyfin\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=Europe/Zurich\n      - JELLYFIN_PublishedServerUrl=jellyfin.one137.dev #optional\n    volumes:\n      - /path/to/jellyfin/library:/config\n      - /path/to/tvseries:/data/tvshows\n      - /path/to/movies:/data/movies\n    ports:\n      - 8096:8096\n      - 8920:8920 #optional\n      - 7359:7359/udp #optional\n      - 1900:1900/udp #optional\n    restart: unless-stopped\nIn Alpine LXC w/ video mount\n💡 In separate LXC container instead of on dockerhost, in case we’d want (and succeed…) to pass the iGPU through.\nSetup\nFirst |mount the shares for Alpine on the Proxmox host (tricky).\nThen in the Alpine LXC:\n# In Proxmox console\n \napk update &amp;&amp; apk add openssh &amp;&amp; rc-update add sshd\nreboot\n \n# Logged in as root through ssh\n \nls -al /mnt/nas-video* # Check content of both folder\ntouch /mnt/nas-video/qq &amp;&amp; rm /mnt/nas-video/qq\ntouch /mnt/nas-video-nfs/qq &amp;&amp; rm /mnt/nas-video-nfs/qq\n \necho &quot;@community &lt;dl-cdn.alpinelinux.org/alpine/latest-stable/community&gt;&quot; &gt;&gt; /etc/apk/repositories\napk add vim jellyfin@community jellyfin-web@community\n \nrc-update add jellyfin\nrc-service jellyfin start\nJellyfin should now be accessible on http://&lt;your_server_ip&gt;:8096. If Swagger API instead, remove opts=&quot;--nowebclient” from /etc/conf.d/jellyfin."},"Homelab/Services/Mailrise":{"title":"Mailrise","links":["Homelab/OS-and-Virtualization/Proxmox"],"tags":[],"content":"Setup\nservices:\n  mailrise:\n    image: yoryan/mailrise\n    container_name: ct-mailrise\n    volumes:\n      - type: bind\n        source: /srv/docker/volumes/mailrise/mailrise.conf\n        target: /etc/mailrise.conf\n        read_only: true\n    # ports:\n    #   - 8025:8025\n    restart: unless-stopped\nmailrise.conf (file needs to be readable by user 999):\nconfigs:\n  proxmox-notices-telegram:\n    urls:\n      - tgram://${TOKEN_ID}/${CHAT_ID}\n    mailrise:\n      body_format: text\n      body_template: &quot; &quot;\nsmtp:\n  auth:\n    basic:\n      ${USER}: ${PASS}\n\nCreate a mailrise.one137.dev stream host in NPM, TCP port 8025.\nConfiguring Proxmox\nCreate an SMTP notification target with:\n\nServer: mailrise.one137.dev\nEncryption: none\nPort: 8025\nFrom address: …\nAdditional recipients: proxmox-notices-telegram@mailrise.xyz\nComment: Send Telegram message\nAuthenticate: On / {USER} / {PASS}\nAuthor (advanced): ” ” ← just a space, Mailrise crashes without that\n"},"Homelab/Services/MongoDB":{"title":"MongoDB","links":["Homelab/Storage/iSCSI"],"tags":[],"content":"Setup\nservices:\n  mongodb:\n    image: mongo:latest\n    container_name: ct-mongodb\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: ${ROOT_USERNAME}\n      MONGO_INITDB_ROOT_PASSWORD: ${ROOT_PASSWORD} \n      GLIBC_TUNABLES: glibc.pthread.rseq=0\n    # ports:\n    #   - 27017:27017\n    networks:\n      - internal\n    volumes: \n      - /srv/docker/volumes/mongodb/db:/data/db\n      - /srv/docker/volumes/mongodb/configdb:/data/configdb\n      # - /mnt/nas-xfs-zvol/db:/data/db\n      # - /mnt/nas-xfs-zvol/configdb:/data/configdb\n    restart: unless-stopped\n \nnetworks:\n  internal:\n    driver: bridge\n    internal: true\nAdd ct-npm to 50-mongodb_internal network\nAdd a stream host to NPM, through the UI or:\ncurl -sX POST -H &quot;Authorization: Bearer ${NPM_TOKEN}&quot; -H &quot;Content-Type:application/json&quot; -d &#039;{&quot;incoming_port&quot;: 27017, &quot;forwarding_port&quot;: 27017, &quot;forwarding_host&quot;: &quot;ct-mongodb&quot;, &quot;tcp_forwarding&quot;: true, &quot;udp_forwarding&quot;: true}&#039; http://localhost:81/api/nginx/streams | jq\nConnect:\nmongosh mongodb://${ROOT_USERNAME}:${ROOT_PASSWORD}@mongodb.one137.dev\nXFS\nTo use an XFS filesystem, see Format and mount a NAS iSCSI drive (XFS for Mongo)\nAddressing Mongo warnings/optimizations\nConnection warning can be suppressed by —quiet (mongosh --quiet mongodb://***:***@mongodb.one137.dev:27017).\nOtherwise, to actually address them (probably only if Mongo lives in its own VM, and if high perf is needed):\n\nsudo vim /etc/sysctl.conf and add vm.max_map_count=1677720 and vm.swappiness=1, then sudo sysctl -p to apply\nAdd following commands to /etc/rc.local if available or create a custom systemd service for them to make them permanent, if needed (not tested):\n\necho always | sudo tee /sys/kernel/mm/transparent_hugepage/enabled\necho defer+madvise | sudo tee /sys/kernel/mm/transparent_hugepage/defrag\necho 0 | sudo tee /sys/kernel/mm/transparent_hugepage/khugepaged/max_ptes_none\n\n\n"},"Homelab/Services/Nginx-Proxy-Manager-(NPM)":{"title":"Nginx Proxy Manager (NPM)","links":["Homelab/Services/DNSMasq","Homelab/Services/Wireguard","Homelab/Services/Homelab-Services","Homelab/Services/Web-Server","Homelab/Internet-Infrastructure/Serve-static-files-through-NPM"],"tags":[],"content":"Simple reverse proxy to expose services with\n\nProxy and stream hosts\nA beginner-friendly UI\nLet’s Encrypt certs generation and auto-renewal\nAccess lists\nUI-toggleable options such as Connection upgrades and Block exploits\nAccess to the underling Nginx configuration and to an API\n\nnginxproxymanager.com/\nThis is the central and unique point through which all services are accessed and guarded by an access list and ssl certificates. Services cannot be accessed directly because they do not expose their own ports. If they use http(s), they’ll be accessible through a proxy host and for other ports, the port should be expose on NPM instead a stream host used.\nSetup\nservices:\n  npm:\n    container_name: ct-npm\n    image: &#039;jc21/nginx-proxy-manager:latest&#039;\n    ports:\n      - &#039;443:443&#039;     # Public HTTPS Port\n      # - &#039;81:81&#039;     # NPM itself, when not configd yet\n      # Streams:\n      - &#039;${WG_PORT}:${WG_PORT}/udp&#039; # Wireguard\n      - &#039;27017:27017&#039; # MongoDB\n      - &#039;8025:8025&#039;   # Mailrise (SMTP)\n    environment:\n      DISABLE_IPV6: &#039;true&#039;\n      PUID: 1001\n      PGID: 1001\n      TZ: Europe/Zurich\n    volumes:\n      - /srv/docker/volumes/one137-web:/srv/docker/volumes/one137-web\n      - /srv/docker/volumes/npm/data:/data\n      - /srv/docker/volumes/npm/letsencrypt:/etc/letsencrypt\n    networks:\n      - portainer_net\n      - 30-pihole_default\n      - 40-wireguard-client_default\n      - 40-wireguard-easy_default\n      - 50-cloudflared_default\n      - 50-jellyfin_default\n      - 50-mailrise_default\n      - 50-mongodb_internal\n      - 60-uptime-kuma_default\n    restart: unless-stopped\n \nnetworks:\n  portainer_net:\n    external: true\n  30-pihole_default:\n    external: true\n  40-wireguard-client_default:\n    external: true\n  40-wireguard-easy_default:\n    external: true\n  50-cloudflared_default:\n    external: true\n  50-jellyfin_default:\n    external: true\n  50-mongodb_internal:\n    external: true\n  50-mailrise_default:\n    external: true\n  60-uptime-kuma_default:\n    external: true\nDefault login:\n\nadmin@example.com\nchangeme\n\nCreate SSL Certificates\n\ndash.cloudflare.com/profile/api-tokens &gt; Create Token\n\none137.dev - Zone:Read, DNS:Edit\n\n\nNPM &gt; SSL certs &gt; Add cert &gt; Let’s encrypt\n\nEnter Domain name(s), Email, “Use a DNS Challenge”\nEnter DNS Provider “Cloudflare” and replace “01234…” with actual token\nLeave Propagation empty, Agree to TCs, Save\n\n\n\nCreate Access List\n\nName: LAN + Wireguard\nSatisfy Any\nAccess: allow 192.168.1.1/24 for LAN, and allow 172.16.0.0/12 or 172.20.0.x/32 for Wireguard\n\nIf DNSMasq is used alongside Wireguard, 172.20.0.x/32, where the IP is that of wireguard-easy on its own docket network: docker exec ct-wireguard-easy ip a | grep 172\nOtherwise, use the entire Docker subnet, 172.16.0.0/12 (see Why)\n\n\n\nCreate Proxies\nExamples (see Homelab Services for full list):\n\npihole1.one137.dev: http://pihole1:80 (pihole1 a local A record)\nnpm.one137.dev: http://ct-npm:81 (ct-npm a container name on docker network)\none137.dev: http://STATIC_FILES:1 (see below)\n\nCreate Streams\nExamples:\n\n27017: ct-mongo:27017 TCP\n8025: ct-mailrise:8025 TCP/UDP\n\nUse the API\ngithub.com/NginxProxyManager/nginx-proxy-manager/tree/develop/backend/schema/paths/nginx.\nExamples:\nGet a token:\ncurl -sX POST -H &quot;Content-Type:application/json&quot; http://localhost:81/api/tokens -d &#039;{&quot;identity&quot;:&quot;$NPM_EMAIL&quot;, &quot;secret&quot;:&quot;$NPM_PASS&quot;}&#039; | jq\nCreate a new Stream host:\ncurl -sX POST -H &quot;Authorization: Bearer ${NPM_TOKEN}&quot; -H &quot;Content-Type:application/json&quot; -d &#039;{&quot;incoming_port&quot;: 8025, &quot;forwarding_port&quot;: 8025, &quot;forwarding_host&quot;: &quot;ct-mailrise&quot;, &quot;tcp_forwarding&quot;: true, &quot;udp_forwarding&quot;: false}&#039; http://localhost:81/api/nginx/streams | jq\nTry using npm.one137.dev/api if port 81 isn’t exposed anymore.\nUse NPM as a Web Server\nSee Serve static files through NPM."},"Homelab/Services/Pi-Hole":{"title":"Pi-Hole","links":["tags/TODO","Homelab/Internet-Infrastructure/Domain-Name,-DNS,-FQDN","Homelab/Services/Homelab-Networking"],"tags":["TODO"],"content":"TODO\nDomain Name, DNS, FQDN\nHomelab Networking\nSetup\nVM / Bare\nIf in Proxmox:\n\nCore: 2, RAM: 2G, Disk: 8G, Network: static IPv4, no IPv6\nSet “Start at boot”, “Start order”\nPaste public ssh key\n\nIn host:\n\ncurl -sSL &lt;install.pi-hole.net&gt; | bash\n\nDocker\ngithub.com/pi-hole/docker-pi-hole/#quick-start\nservices:\n  pihole:\n    container_name: ct-pihole\n    image: pihole/pihole:latest\n    ports:\n      - &#039;53:53/tcp&#039;\n      - &#039;53:53/udp&#039;\n    environment:\n      TZ: &#039;Europe/Zurich&#039;\n      WEBPASSWORD: ${WEBPASSWORD}\n      DNSMASQ_LISTENING: all\n      FTLCONF_LOCAL_IPV4: 192.168.1.101\n      PIHOLE_DNS_: 1.1.1.1;1.0.0.1\n      WEBTHEME: default-dark\n      VIRTUAL_HOST: pihole2.one137.dev\n    volumes:\n      - &#039;/srv/docker/volumes/pihole/etc-pihole:/etc/pihole&#039;\n      - &#039;/srv/docker/volumes/pihole/etc-dnsmasq.d:/etc/dnsmasq.d&#039;\n    restart: unless-stopped\nAdd ct-npm to 30-pihole_default network.\nPost install\nVerify that pi.hole points to the correct server (same as e.g. http://192.168.1.98/admin)\nConfigure Local DNS &gt; DNS Records for all services or import Teleporter backup file.\nOnce fully set up, backup config through UI &gt; Settings &gt; Teleporter &gt; Backup\nTo redirect / to /admin, see discourse.pi-hole.net/t/redirect-to-admin/44103 for bare installs. For Docker, the VIRTUAL_HOST is already set above.\nCustom DNSMasq files\nFor general domain access, instead of CNAMEs:\n/etc/dnsmasq.d/98-one137-address.conf:\naddress=/one137.dev/172.20.0.3 # Direct to NPM for wireguard clients\naddress=/one137.dev/192.168.1.101\n\nwhere\n\n192.168.1.101 is dockerhost’s address\n172.20.0.0/16 is network 40-wireguard-easy_default’s subnet and\n172.20.0.3 is ct-npm’s address on that network.\n\nTo have both primary and secondary DNS servers announced by the DHCP primary:\n/etc/dnsmasq.d/99-second-DNS.conf:\ndhcp-option=option:dns-server,192.168.1.98,192.168.1.101\n\nQuery API\npi.hole/admin/api.php\nRedundancy\nPi-hole 1\nRuns primary pi-hole instance with DHCP server\nPi-hole 2\nSecondary instance w/o DHCP"},"Homelab/Services/Portainer":{"title":"Portainer","links":[],"tags":[],"content":"Setup\ndocs.portainer.io/start/install-ce/server/docker/linux\nFind out the latest tag at hub.docker.com/r/portainer/portainer-ce/tags\ndocker network create portainer_net\n \ndocker run -d --name ct-portainer \\\n\t-p 9443:9443 --network portainer_net --restart=always \\\n\t-v /var/run/docker.sock:/var/run/docker.sock \\\n\t-v /srv/docker/volumes/portainer/data:/data \\\n\tportainer/portainer-ce:2.24.1\n\n\n                  \n                  NOTE\n                  \n                \n\nPort 9443 need to be exposed even after NPM/portainer.one137.dev has been configured, because the NPM stack cannot be edited from proxied portainer.one137.dev\nPort 8000 is optional and only required if using Edge Compute features with Edge Agents\n\n\nUI at https://192.168.1.101:9443\nPrereq for import/export below\nCreate API token:\n\nClick account name (top-right) &gt; My account\nAccess tokens &gt; Add access token &gt; Copy and save token\n\nInstall jq\n\nsudo apt install jq\n\nImport stacks from CLI\nMake sure you have a Portainer Access Token configured.\ncurl -k -X POST &quot;https://localhost:9443/api/stacks/create/standalone/file?endpointId=2&quot; -H &quot;X-API-Key: $PORTAINER_TOKEN&quot; -F &#039;Name=50-cloudflared&#039; -F &#039;file=@50-cloudflared.yml&#039; -F &quot;Env=$(cat ./50-cloudflared.secrets.env.json)&quot;\n\nwhere 50-cloudflared.secrets.env.json looks like:\n[{ &quot;name&quot;: &quot;CLOUDFLARED_TOKEN&quot;, &quot;value&quot;: &quot;ey...J9&quot; }]\n\nAutomate:\n\nPORTAINER_API_TOKEN=&lt;token&gt; ./import_stacks.sh\nwhere script is:\n\n#!/bin/bash\n \nPORTAINER_URL=&quot;https://localhost:9443/api&quot;\nINPUT_DIR=&quot;./stacks&quot;\n \nif [[ ! &quot;$PORTAINER_API_TOKEN&quot; ]]; then\n    echo &quot;Please define \\$PORTAINER_API_TOKEN&quot;\n    exit 1\nfi\n \nif ! command -v jq &gt; /dev/null 2&gt;&amp;1; then\n    echo &quot;Please install jq&quot;\n    exit 1\nfi\n \n# Query Portainer API to get the endpointId\n \nresponse=$(curl -ks &quot;$PORTAINER_URL/endpoints&quot; -H &quot;X-API-Key: $PORTAINER_API_TOKEN&quot;)\nendpoint_count=$(echo &quot;$response&quot; | jq &#039;. | length&#039;)\n \nif [[ &quot;$endpoint_count&quot; -eq 1 ]]; then\n    endpoint_id=$(echo &quot;$response&quot; | jq -r &#039;.[0].Id&#039;)\n    echo &quot;Using endpointId: $endpoint_id&quot;\nelse\n    echo &quot;Error: No or multiple endpoints found. Try running:&quot;\n    echo &quot; curl -ks \\&quot;$PORTAINER_URL/endpoints\\&quot; -H \\&quot;X-API-Key: \\$PORTAINER_API_TOKEN\\&quot; | jq&quot;\n    exit 1\nfi\n \n# Create the stacks\n \necho -e &quot;Reading $INPUT_DIR/*.yml files...\\n&quot;\nfor yml_file in $INPUT_DIR/*.yml; do\n    base_name=$(basename &quot;$yml_file&quot; .yml) # e.g. &quot;30-st-pihole&quot; from &quot;stacks/30-st-pihole.yml&quot;\n    echo &quot;* Creating stack $base_name&quot;\n \n    env_file=&quot;$INPUT_DIR/${base_name}.env.json&quot;\n    if [[ -f &quot;$env_file&quot; ]]; then\n        curl -k -X POST &quot;$PORTAINER_URL/stacks/create/standalone/file?endpointId=$endpoint_id&quot; \\\n             -H &quot;X-API-Key: $PORTAINER_API_TOKEN&quot; \\\n             -F &quot;Name=$base_name&quot; \\\n             -F &quot;file=@$yml_file&quot; \\\n             -F &quot;Env=$(cat &quot;$env_file&quot;)&quot;\n    else\n        curl -k -X POST &quot;$PORTAINER_URL/stacks/create/standalone/file?endpointId=$endpoint_id&quot; \\\n             -H &quot;X-API-Key: $PORTAINER_API_TOKEN&quot; \\\n             -F &quot;Name=$base_name&quot; \\\n             -F &quot;file=@$yml_file&quot;\n    fi\n    echo -e &quot;\\n&quot;\ndone\nExport all stacks\n./export_all_stacks.sh :\n#!/bin/bash\n \n# Constants\nPORTAINER_URL=&quot;https://localhost:9443&quot; # &quot;portainer.one137.dev&quot;\nOUTPUT_DIR=&quot;./stacks-$(date +%Y%m%d-%H%M%S)&quot;\n \nif [[ -z &quot;$PORTAINER_API_TOKEN&quot; ]]; then\n    echo &quot;Please define \\$PORTAINER_API_TOKEN&quot;\n    exit 1\nfi\n \nif ! command -v jq &gt; /dev/null; then\n    echo &quot;Please install jq&quot;\n    exit 1\nfi\n \nmkdir -p &quot;$OUTPUT_DIR&quot;\n \nSTACKS=$(curl -sk &quot;$PORTAINER_URL/api/stacks&quot; -H &quot;X-API-Key: $PORTAINER_API_TOKEN&quot;)\nif [[ $? -ne 0 || -z &quot;$STACKS&quot; ]]; then\n    echo &quot;Error: Failed to fetch stacks.&quot;\n    exit 1\nfi\n \nSTACK_LIST=$(echo &quot;$STACKS&quot; | jq -c &#039;.[] | {id: .Id, name: .Name}&#039;)\nif [[ -z &quot;$STACK_LIST&quot; ]]; then\n    echo &quot;Error: No stacks found.&quot;\n    exit 1\nelse\n    echo -e &quot;Successfully fetched all stacks.\\n&quot;\nfi\n \necho &quot;$STACK_LIST&quot; | while read -r STACK; do\n    STACK_ID=$(echo &quot;$STACK&quot; | jq -r &#039;.id&#039;)\n    STACK_NAME=$(echo &quot;$STACK&quot; | jq -r &#039;.name&#039;)\n \n    echo &quot;Processing stack: $STACK_NAME (ID: $STACK_ID)&quot;\n \n    STACK_FILE=$(curl -sk &quot;$PORTAINER_URL/api/stacks/$STACK_ID/file&quot; -H &quot;X-API-Key: $PORTAINER_API_TOKEN&quot; | jq -r &#039;.StackFileContent&#039;)\n    if [[ $? -ne 0 || -z &quot;$STACK_FILE&quot; ]]; then\n        echo &quot;  Warning: Failed to fetch stack file. Skipping.&quot;\n        continue\n    fi\n    YML_PATH=&quot;$OUTPUT_DIR/$STACK_NAME.yml&quot;\n    echo &quot;$STACK_FILE&quot; &gt; &quot;$YML_PATH&quot;\n    echo &quot;  Saved stack file to $YML_PATH&quot;\n \n    STACK_ENV=$(curl -sk &quot;$PORTAINER_URL/api/stacks/$STACK_ID&quot; -H &quot;X-API-Key: $PORTAINER_API_TOKEN&quot; | jq -r &#039;.Env&#039;)\n    if [[ $? -eq 0 &amp;&amp; &quot;$STACK_ENV&quot; != &quot;null&quot; ]]; then\n        ENV_PATH=&quot;$OUTPUT_DIR/$STACK_NAME.env.json&quot;\n        echo &quot;$STACK_ENV&quot; &gt; &quot;$ENV_PATH&quot;\n        chmod go-rwx &quot;$ENV_PATH&quot;\n        echo &quot;  Saved environment variables to $ENV_PATH&quot;\n    else\n        echo &quot;  No environment variables found.&quot;\n    fi\n \n    echo\ndone\n\nFor each stack, export its secrets to stacks-name.secrets.env.json\n"},"Homelab/Services/Syncthing":{"title":"Syncthing","links":[],"tags":[],"content":"Setup\nIn TrueNAS\n\nCreate syncthing dataset, type Generic (not samba!)\n\nOwner probably needs to be 1000:1000\n\n\nAdd app\n\nUID GID 1000\nConfig  storage &gt; Host path &gt; choose created dataset\n4 CPUs, 8196 MB\n\n\n\nIn Syncthing UI\n\nActions, Settings:\n\nSet device name: truenas\nSet GUI auth (+check https if usually proxied)\nEdit Folder Defaults:\n\nFolder Path: ~/data\nIgnore Patterns: // #include .stglobalignore\nAdvanced: Folder Type: Receive Only\n\n\n\n\nAdd Remote Device\n\nChoose e.g. IZD4UKL\nSharing: Auto-accept\nAccept new device (truenas) from other device (IZD4UKL) and check folders to sync\nOnce syncs finished, uncomment line in “ignore patterns”\n\n\n\nservices:\n  syncthing:\n    image: syncthing/syncthing\n    container_name: syncthing\n    hostname: my-syncthing\n    environment:\n      - PUID=1001\n      - PGID=1001\n    volumes:\n      - /wherever/st-sync:/var/syncthing\n    ports:\n      - 8384:8384 # Web UI\n      - 22000:22000/tcp # TCP file transfers\n      - 22000:22000/udp # QUIC file transfers\n      - 21027:21027/udp # Receive local discovery broadcasts\n    restart: unless-stopped\n    healthcheck:\n      test: curl -fkLsS -m 2 127.0.0.1:8384/rest/noauth/health | grep -o --color=never OK || exit 1\n      interval: 1m\n      timeout: 10s\n      retries: 3\n"},"Homelab/Services/Transmission":{"title":"Transmission","links":["Homelab/Services/Wireguard"],"tags":[],"content":"Transmission\nCreate TrueNAS dataset and share with SMB: “video”\nAdd to /etc/fstab:\n//192.168.1.100/video /mnt/video-nas cifs credentials=/etc/samba/truenas-sambaguest,uid=1001,gid=1001,file_mode=0664,dir_mode=0775,x-systemd.automount 0 0\ngithub.com/linuxserver/docker-transmission#docker-compose-recommended-click-here-for-more-info:\nservices:\n  transmission:\n    image: lscr.io/linuxserver/transmission:latest\n    container_name: ct-transmission\n    environment:\n      - PUID=1001\n      - PGID=1001\n      - TZ=Europe/Zurich\n      - USER=${USER}\n      - PASS=${PASS}\n    volumes:\n      - /srv/docker/volumes/transmission:/config\n      - /mnt/video-nas/torrent:/downloads\n      - /mnt/video-nas/torrent/watch:/watch\n    network_mode: &quot;container:ct-wireguard-client&quot; # To route all trafic thru the VPN\n    # ports:\n    #   - 9091:9091\n    #   - 51413:51413\n    #   - 51413:51413/udp\n    restart: unless-stopped\nMake sure the PIDs in docker-compose are the same as in fstab.\nUI  on port 9091.\nct-npm needs to be added to 40-wireguard-easy_default network and proxy transmission.one137.dev traffic to http://ct-wireguard-client:9091 for UI to be accessible.\nSee Test connection (with ct-transmission instead of ct-wireguard-client) to ensure transmission has internet access."},"Homelab/Services/Uptime-Kuma":{"title":"Uptime-Kuma","links":["Homelab/Services/Healthchecks"],"tags":[],"content":"Service monitoring tool with fancy UI.\n\nMonitoring uptime for HTTP(S) / TCP / Keyword and Json Query / Ping / DNS Record / Docker Containers / etc\nNotifications via Telegram, Pushover, SMTP, and 90 more\nMultiple status pages, Mappable to specific domains\nPing chart, Certificate info, and much more.\n\ngithub.com/louislam/uptime-kuma\nSetup\nservices:\n  uptime-kuma:\n    image: louislam/uptime-kuma:1\n    container_name: ct-uptime-kuma\n    restart: unless-stopped\n    # ports:\n    #   - &quot;3001:3001&quot;\n    # environment:\n    #   PUID: 1001 # Cannot be used for Docker host connection\n    #   PGID: 1001\n    volumes:\n      - /srv/docker/volumes/uptime-kuma:/app/data\n      - /var/run/docker.sock:/var/run/docker.sock:ro   \nSettings\nGeneral:\n\nPrimary Base URL: uptime-kuma.one137.dev\nAppearance:\nDark\nNotifications &gt; Setup:\nTelegram\nToken and ChatID from password manager\nDefault enabled, Apply on all existing monitors\nReverse Proxy:\nTrust Proxy: yes\nDocker Hosts &gt; Setup:\nDefault values\n\nAdd Monitors\nAdd a Docker monitor for each Docker container\nAdd an HTTP monitor for other services (truenas, syncthing)\nAdd a DNS monitor for pihole1\nAdd an HTTP-Keyword monitor for one137.dev\nAdd an HTTP for monitor for Healthchecks (hc-ping.com/(uuid), 300s)"},"Homelab/Services/Web-Server":{"title":"Web Server","links":["tags/TODO","Homelab/Internet-Infrastructure/Serve-static-files-through-NPM","Homelab/Internet-Infrastructure/Continuous-Delivery-of-website"],"tags":["TODO"],"content":"TODO\n\nServe static files through NPM\nContinuous Delivery of website\nObsidian\nQuartz\n"},"Homelab/Services/Wireguard":{"title":"Wireguard","links":["Homelab/Services/DNSMasq"],"tags":[],"content":"WireGuard is a simple, fast, modern, general purpose VPN that utilizes state-of-the-art cryptography. It aims to be faster, simpler, leaner, and more useful than IPsec, and considerably more performant than OpenVPN.\nwww.wireguard.com/\nWireguard Server\ngithub.com/wg-easy/wg-easy:\nservices:\n  dnsmasq: # Provides &quot;address=/one137.dev/172.20.0.x&quot; (NPM IP) to wg-easy\n    image: 4km3/dnsmasq\n    container_name: ct-dnsmasq-wireguard\n    cap_add:\n      - NET_ADMIN\n    volumes:\n      - /srv/docker/volumes/dnsmasq-wireguard/dnsmasq.conf:/etc/dnsmasq.conf\n    restart: unless-stopped\n  wireguard-easy:\n    image: ghcr.io/wg-easy/wg-easy\n    container_name: ct-wireguard-easy\n    volumes:\n      - /srv/docker/volumes/wireguard-easy:/etc/wireguard\n    environment:\n      - LANG=en\n      - WG_HOST=${WG_HOST}\n      # Optional:\n      - PASSWORD_HASH=${PASSWORD_HASH}\n      - WG_PORT=${WG_PORT}\n      - WG_DEFAULT_DNS=172.20.0.2 # DNSMasq IP, or &quot;192.168.1.98, 192.168.1.101&quot;\n      - WG_ALLOWED_IPS=192.168.1.0/24\n      - WG_PERSISTENT_KEEPALIVE=30\n      - UI_TRAFFIC_STATS=true\n      - UI_CHART_TYPE=2 # (0 disabled, 1 Line, 2 Area, 3 Bar)\n    restart: unless-stopped\n    cap_add:\n      - NET_ADMIN\n      - SYS_MODULE\n    sysctls:\n      - net.ipv4.ip_forward=1\n      - net.ipv4.conf.all.src_valid_mark=1\nNote: DNSMasq is an optional and debatable addition. See Why.\nAdd ct-npm to 40-wireguard-easy_default network.\nSetup 51820 (or ${WG_PORT}) stream in NPM, through the UI or:\ncurl -sX POST -H &quot;Authorization: Bearer ${NPM_TOKEN}&quot; -H &quot;Content-Type:application/json&quot; -d &#039;{&quot;incoming_port&quot;: 51820, &quot;forwarding_port&quot;: 51820, &quot;forwarding_host&quot;: &quot;ct-wireguard-easy&quot;, &quot;tcp_forwarding&quot;: false, &quot;udp_forwarding&quot;: true}&#039; http://localhost:81/api/nginx/streams | jq\nOn the router, forward UDP port 51820/${WG_PORT} to dockerhost/192.168.1.101:51820/${WG_PORT}.\nIf using a custom DNSMasq as default DNS server, make sure to set the correct IP in WG_DEFAULT_DNS. See DNSMasq.\nWireguard Client\nservices:\n  wireguard-client:\n    image: lscr.io/linuxserver/wireguard:latest\n    container_name: ct-wireguard-client\n    cap_add:\n      - NET_ADMIN\n    environment:\n      - PUID=1001\n      - PGID=1001\n      - TZ=Europe/Zurich\n    volumes:\n      - /srv/docker/volumes/wireguard-client:/config\n    # ports:\n    #   - 52001:52001/udp\n    sysctls:\n      - net.ipv4.conf.all.src_valid_mark=1\n    restart: unless-stopped\nAdd VPN client config to /srv/docker/volumes/wireguard-client/wg_confs/wg0.conf (file with “[Interface]”, “[Peer]”, etc.), chown/chmod dockeruser/600.\nAdd ct-npm to 40-wireguard-client_default network.\nForce other containers to use Wireguard for their traffic by setting network_mode: &quot;container:ct-wgclient&quot; in their stack.\nRestarting this container requires restarting (possibly recreating) other containers using it for their network.\nTest VPN connection\ndocker exec -it ct-wireguard-client /bin/bash\nping 1.1.1.1\ncurl am.i.mullvad.net/json # look for &quot;mullvad_exit_ip&quot;:true"},"Homelab/Services/ddclient":{"title":"ddclient","links":["Homelab/Internet-Infrastructure/DynDNS"],"tags":[],"content":"Simple CLI DynDNS service.\nSetup\ngithub.com/linuxserver/docker-ddclient\n/srv/docker/volumes/ddclient/ddclient.conf:\ndaemon=300\nsyslog=yes\nmail-failure=root\npid=/var/run/ddclient/ddclient.pid\nssl=yes\n \nuse=web, web=ipify-ipv4\nprotocol=cloudflare, \\\nzone=one137.dev, \\\nttl=1, \\\nlogin=token, \\\npassword=&lt;password&gt; \\\n&lt;sub&gt;.one137.dev\nchmod 600 ddclient.conf\nStack:\nservices:\n  ddclient:\n    image: lscr.io/linuxserver/ddclient:latest\n    container_name: ct-ddclient\n    environment:\n      - PUID=1001\n      - PGID=1001\n      - TZ=Europe/Zurich\n    volumes:\n      - /srv/docker/volumes/ddclient:/config\n    restart: unless-stopped"},"Homelab/Storage/NAS-Data-Protection":{"title":"NAS Data Protection","links":["Homelab/OS-and-Virtualization/TrueNAS","Homelab/Services/Syncthing"],"tags":[],"content":"TrueNAS\nSyncthing"},"Homelab/Storage/NVMe":{"title":"NVMe","links":["Homelab/OS-and-Virtualization/Proxmox"],"tags":[],"content":"Non-Volatile Memory Express\nis an open, logical-device interface specification for accessing a computer’s storage attached via the PCI Express bus.\nNVM Express has been designed to capitalize on the low latency and internal parallelism of SSD devices.\nIt is a software protocol, using the PCIe hardware interface.\nSource: Wikipedia\nSetup\nSee IOMMU for NVMe IOMMU related commands"},"Homelab/Storage/Network-Shares":{"title":"Network Shares","links":["Homelab/OS-and-Virtualization/TrueNAS","Homelab/Storage/iSCSI"],"tags":[],"content":"TrueNAS\niSCSI\nSMB\nIn TrueNAS\n\nDatasets: Add dataset\nDataset Preset: SMB\n(Add to Proxmox)\n\nDC, Storage, Add, SMB/CIFS\nID: e.g. truenas-proxmox\nCan check all content types\nUsername “USER” / Password: TrueNAS’s “USER” user account\n\n\n\nOn target system\nsudo apt install cifs-utils\n \nsudo mkdir /etc/samba/\nsudo vim /etc/samba/truenas-sambaguest\n###\nusername=sambaguest\npassword=***\n###\n \nsudo chmod 600 /etc/samba/truenas-sambaguest\n \nsudo mkdir /mnt/video-nas\nsudo vim /etc/fstab\n### Add lines (IP address of TrueNAS)\n//192.168.1.100/video /mnt/video-nas cifs credentials=/etc/samba/truenas-sambaguest,uid=1001,gid=1001,file_mode=0664,dir_mode=0775,x-systemd.automount 0 0\n###\n \nsudo mount /mnt/video-nas/ # to test\nIf target system is a Synology NAS\nUI &gt; File Station &gt; Tools &gt; Mount remote folder &gt; CIFS\nTime Machine over SMB in TrueNAS\nIn TrueNAS:\n\nSystem &gt; SMB &gt; Edit &gt; Advanced &gt; Enable Apple SMB2/3 Protocol Extensions\nShares &gt; SMB &gt; (create or edit desired share) &gt; Purpose = Multi-user time machine\nIn macOS:\nConnect to the share (Finder &gt; Cmd-K)\nGo to Settings &gt; Time Machine to add the share\n\niSCSI\nSee iSCSI\nNFS\nNote: SMB is more performant\nOn NAS\n\nShare /mnt/main-pool/video as NFS\nSet “mapall user” and “mapall group” to “root”\n\nNote: probably better to change ownership of dataset to doran and mapall to doran\n\n\n\nMounting shares from unprivileged LXC\nSMB is tricky if LXC is not privileged. However, a workaround is to Bind-Mount the CIFS Share from the Host then map the Container user to the Host user with idmap. LXC container configs are located at /etc/pve/lxc/&lt;container_id&gt;.conf\nExample mounting TrueNAS’s “video” share as both SMB and NFS. This maps LXC user 100:101 to Host user 1000:1000.\nOn Proxmox host:\nvim /etc/fstab\n### Add (see elsewhere for &quot;/etc/samba/truenas-doran&quot;)\n//192.168.1.100/video /mnt/nas-video-jelly cifs credentials=/etc/samba/truenas-doran,uid=1000,gid=1000 0 0\n192.168.1.100:/mnt/main-pool/video /mnt/nas-video-jelly-nfs nfs defaults 0 0\n###\n \nsystemctl daemon-reload\nls -al /mnt/nas-video-jelly* # Check content of both folder\ntouch /mnt/nas-video-jelly/qq &amp;&amp; rm /mnt/nas-video-jelly/qq\ntouch /mnt/nas-video-jelly-nfs/qq &amp;&amp; rm /mnt/nas-video-jelly-nfs/qq\n \nvim /etc/subuid /etc/subgid\n### Set both files&#039; content to\nroot:1000:1\nroot:100000:65536\n###\n \nvim /etc/pve/lxc/CONTAINER_ID.conf\n### Add\nmp0: /mnt/nas-video-jelly,mp=/mnt/nas-video\nmp1: /mnt/nas-video-jelly-nfs,mp=/mnt/nas-video-nfs\nlxc.idmap: u 0 100000 100\nlxc.idmap: g 0 100000 101\nlxc.idmap: u 100 1000 1\nlxc.idmap: g 101 1000 1\nlxc.idmap: u 101 101001 64535\nlxc.idmap: g 102 101002 64534\n###\n \npct reboot CONTAINER_ID\nNow the mount should be available and writable from within the LXC."},"Homelab/Storage/PCIe":{"title":"PCIe","links":[],"tags":[],"content":"PCI Express (Peripheral Component Interconnect Express) is a high-speed serial computer expansion bus standar.\nIt is the common motherboard interface for personal computers’ graphics cards, capture cards, sound cards, hard disk drive host adapters, SSDs, Wi-Fi, and Ethernet hardware connections.\nPCIe has numerous improvements over the older standards, including higher maximum system bus throughput, lower I/O pin count and smaller physical footprint, better performance scaling for bus devices, a more detailed error detection and reporting mechanism and native hot-swap functionality. More recent revisions of the PCIe standard provide hardware support for I/O virtualization.\nThe PCI Express electrical interface is measured by the number of simultaneous lanes. A lane is a single send/receive line of data, analogous to a “one-lane road” having one lane of traffic in both directions.\nSource: Wikipedia"},"Homelab/Storage/SATA":{"title":"SATA","links":["Homelab/Storage/PCIe","Homelab/Storage/NVMe","Homelab/Storage/SCSI"],"tags":[],"content":"PCIe\nNVMe\nSCSI"},"Homelab/Storage/SCSI-vs-NVMe-vs-AHCI-(SATA)":{"title":"SCSI vs NVMe vs AHCI (SATA)","links":["Homelab/Storage/SCSI","Homelab/Storage/NVMe"],"tags":[],"content":"SCSI, NVMe and AHCI are low-level software protocols designed to manage communication between storage devices (e.g., HDDs, SSDs) and a host system (e.g., CPU, OS).\nAHCI is to SATA what NVMe is to PCIe (more or less?).\nCommon points\n\nPurpose:\n\nAll three are protocols designed to manage communication between storage devices (e.g., HDDs, SSDs) and a host system (e.g., CPU, OS).\n\n\nBlock-Level Storage:\n\nAll three manage block-level storage, meaning they operate by reading and writing fixed-size blocks of data.\n\n\nQueuing Mechanisms:\n\nThey implement mechanisms to queue and process I/O requests. This allows multiple storage operations to be handled simultaneously, improving performance.\n\n\nDevice Management:\n\nThey provide command sets for performing tasks like reading/writing data, checking device status, and handling errors.\n\n\nHot-Swapping\n\nSupport for their respective hardware interface.\n\n\n\nKey Differences Between AHCI, SCSI, and NVMe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAspectSCSIAHCINVMeDesign PurposeInitially designed for enterprise systems and versatile devices, including HDDs, tape drives, and SSDs.Optimized for SATA-based HDDs and early SSDs.Specifically designed for high-speed SSDs.AgeOriginated in the 1980s (legacy with modern extensions like SAS).Introduced in 2004 (legacy technology).Introduced in 2011, built for modern flash storage.Connection MediumWorks over multiple mediums (e.g., SAS, Fibre Channel, iSCSI).Works over SATA interface.Works over PCIe interface.PerformancePerformance varies (SAS up to 12 Gbps; others depend on medium).Limited by SATA (up to 6 Gbps).PCIe Gen 4 x4 supports up to 64 Gbps.QueuingMultiple queues with up to 256 commands each (SAS).Single queue with 32 commands.64K queues, each supporting 64K commands.EfficiencyModerate latency and overhead (depends on medium).Higher latency and overhead (due to legacy design).Low latency and high efficiency, designed for SSDs.Power ManagementModerate power management (better with SAS).Basic power management features.Advanced power management features for SSDs.Use CaseEnterprise systems requiring reliability and versatility.Consumer-level desktops/laptops with SATA SSDs or HDDs.High-performance systems (e.g., gaming, data centers).Command SetExtensive command set for diverse storage types.AHCI commands are simpler and less optimized for SSDs.Streamlined command set optimized for SSDs.\nSource: ChatGPT"},"Homelab/Storage/SCSI":{"title":"SCSI","links":[],"tags":[],"content":"Small Computer System Interface\nis a set of standards for physically connecting and transferring data between computers and peripheral devices, best known for its use with storage devices.\nSCSI was introduced in the 1980s and has seen widespread use on servers and high-end workstations\nThe SCSI standards define commands, protocols, electrical, optical and logical interfaces.\nIt is mainly a software protocol, using various hardware interface.\nSource: Wikipedia"},"Homelab/Storage/XFS":{"title":"XFS","links":["Homelab/Storage/ZFS","Homelab/Services/MongoDB"],"tags":[],"content":"ZFS\nMongoDB"},"Homelab/Storage/ZFS-Dataset--and--Zvol":{"title":"ZFS Dataset & Zvol","links":["Homelab/Storage/ZFS"],"tags":[],"content":"ZFS\nEncryption\nThere’s rarely a reason to choose CCM over GCM. GCM is generally preferred because it’s faster, more widely supported, and offers built-in integrity verification, making it a better choice for most use cases. Stick with GCM unless you have a specific need for CCM (e.g., compatibility with an older system). ChatGPT"},"Homelab/Storage/ZFS-VDEV--and--Storage":{"title":"ZFS VDEV & Storage","links":["Homelab/Storage/ZFS"],"tags":[],"content":"ZFS"},"Homelab/Storage/ZFS":{"title":"ZFS","links":["Homelab/Storage/ZFS-VDEV--and--Storage","Homelab/Storage/ZFS-Dataset--and--Zvol"],"tags":[],"content":"ZFS is a file system with volume management capabilities. It began as part of Sun Microsystems’ Solaris OS in 2001. In 2013, OpenZFS was founded to coordinate the development of open source ZFS.\nThe management of stored data generally involves two aspects:\n\nthe physical volume management of one or more block storage devices, including their organization into logical block devices as VDEVs (ZFS Virtual Device) as seen by the operating system\nand the management of data and files that are stored on these logical block devices (a file system or other data storage).\n\nZFS is unusual in that it unifies both of these roles and acts as both the volume manager and the file system.\nZFS is designed to ensure that data stored on disks cannot be lost due to physical errors, mis-processing by the hardware or operating system, or bit rot events and data corruption that may happen over time. Its complete control of the storage system is used to ensure that every step, whether related to file management or disk management, is verified, confirmed, corrected if needed, and optimized, in a way that the storage controller cards and separate volume and file systems cannot achieve.\nZFS also includes a mechanism for ZFS Dataset &amp; Zvol and pool-level snapshots and replication, including snapshot cloning, which is described by the FreeBSD documentation as one of its “most powerful features”. Very large numbers of snapshots can be taken without degrading performance. Snapshots can be rolled back “live” or previous file system states can be viewed. They can also be cloned to form new independent file systems.\nSource: Wikipedia (edited)"},"Homelab/Storage/iSCSI":{"title":"iSCSI","links":["Homelab/Storage/SCSI"],"tags":[],"content":"Internet SCSI\nis an IP-based storage networking standard for linking data storage facilities. iSCSI provides block-level access to storage devices by carrying SCSI commands over a TCP/IP network.\nThe protocol allows clients (called initiators) to send SCSI commands to storage devices (targets) on remote servers. It is a storage area network (SAN) protocol, allowing organizations to consolidate storage into storage arrays while providing clients (such as database and web servers) with the illusion of locally attached SCSI disks.\nSource: Wikipedia\nFormat and mount a NAS iSCSI drive (XFS for Mongo)\nIn TrueNAS\nShares &gt; Block (iSCSI) &gt; Wizard\n\n(non-specified mandatory options as per their default, non-mandatory ones empty)\nCreate or Choose Block Device: Select existing Zvol or create a new one. Name and Size can be whatever\nPortal: IP Address: 192.168.1.100 (0.0.0.0 works too)\nInitiator: leave empty or enter mongohost’s IQN, e.g. iqn.1993-08.org.mongohost:01:32b26b160c7, cf sudo cat /etc/iscsi/initiatorname.iscsi\n\nOn target system\nsudo apt update &amp;&amp; sudo apt install -y open-iscsi xfsprogs\n \n# Connect iSCSI device\n \nsudo iscsiadm -m discovery -t sendtargets -p truenas # Eg: 192.168.1.100:3260,1 iqn.2005-10.org.freenas.ctl:xfs-iscsi\nsudo iscsiadm -m node -T iqn.2005-10.org.freenas.ctl:xfs-iscsi -p 192.168.1.100:3260 --login\nlsblk # or `ls -l /dev/disk/by-path/` to identify new device =&gt; Eg: /dev/sdb\n \n# Format to XFS if needed\n \nlsblk -f /dev/sdb # Check if filesystem already formatted. If so, skip to mount\nsudo mkfs.xfs /dev/sdb # If needed\n \n# Mount (test)\n \nsudo mkdir /mnt/nas-xfs\nsudo mount /dev/sdb /mnt/nas-xfs &amp;&amp; ls -al /mnt/nas-xfs # To test\nsudo chown 999:999 /mount/point # If needed, to match a certain user\n \n# Auto mount\n \nsudo iscsiadm -m node -T iqn.2005-10.org.freenas.ctl:xfs-iscsi -p 192.168.1.100:3260 --op update -n node.startup -v automatic # Will modify /etc/iscsi/nodes/iqn.2005-10.org.freenas.ctl:xfs-iscsi/192.168.1.100,3260,1/default\nsudo vim /etc/fstab # Add &quot;/dev/sdb /mnt/nas-xfs xfs defaults,nofail,x-systemd.requires=iscsi.service 0 0&quot;\nsudo reboot # To test\n \n# If dockerd starts before iscsid, i.e. Mongo is not using the mounted XFS filesystem\nsudo systemctl edit docker.service\n### Add near the top\n[Unit]\nAfter=iscsid.service\nRequires=iscsid.service\n###\nTODO: Why is the nofail option necessary? According to sudo journalctl -b, the iSCSI drive is connected before the mount attempt for /mnt/nas-xfs-zvol and so it shouldn’t be a problem"},"index":{"title":"Welcome to one137","links":["Homelab/Homelab","Homelab/Services/Homelab-Services"],"tags":[],"content":"This is my repository of thoughts and learnings.\nA small subset of what I write in my Obsidian vault gets published here.\nAt the moment, all the published content is about my Homelab: a self-hosting experiment to enjoy the IT services I need – for free and with full control – and, more importantly, to hack around and learn about IT infrastructure and related topics.\nThe pages’ content also serves a dual role:\n\nremembering what I’ve done and how, to be able to replicate all setups from scratch,\nwriting down some of the things I’ve learned, to understand and remember them better.\n\nI took a pedagogical approach in a few places. But the majority of the text is written for myself with no attempt to cover what I already know, so the explanatory depth may seem quite inconsistent. Since you’ve stumbled upon these pages, I hope that you find something of value nevertheless."}}